{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","toc_visible":true,"authorship_tag":"ABX9TyM0yUcSU1Sv54Gwv6qV+u/0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#**CHAPTER 4. HYPOTHESIS TO BACKTEST GATE**\n","---"],"metadata":{"id":"rgzq7ad4oQsb"}},{"cell_type":"markdown","source":["##REFERENCE"],"metadata":{"id":"nBRtjho5h2Cg"}},{"cell_type":"markdown","source":["https://chatgpt.com/share/699615c3-5128-8012-a718-a31519ea55b0"],"metadata":{"id":"SCQp1W1bWDl0"}},{"cell_type":"markdown","source":["##0.CONTEXT"],"metadata":{"id":"qWHgDkx8h5mE"}},{"cell_type":"markdown","source":["**Introduction — Notebook 4 (N4): Trading Hypothesis + Backtest Wrapper as a Tool-Augmented LangGraph System**\n","\n","In real trading and research teams, the first thing that breaks is not a strategy. The first thing that breaks is the workflow. A junior analyst has an idea, runs a quick backtest, sends a chart, and a week later nobody can reproduce the result. Another analyst tweaks one parameter “just to see,” and the tweak becomes the new baseline without any trace of why. A portfolio manager asks, “What exactly did you test?” and the answer is a bundle of notebooks, half-remembered assumptions, and a spreadsheet with unexplained filters. The problem is not a lack of intelligence. The problem is that the work is not stateful, not reviewable, and not governed.\n","\n","This notebook treats that workflow failure as the primary engineering objective. We implement a minimal, fast, auditable research loop using **LangGraph**: an agent proposes a hypothesis, a deterministic tool executes a backtest on synthetic data, and a reviewer decides whether the system should iterate or stop. The emphasis is not “prompting” or “alpha.” The emphasis is that the system behaves like a controlled process: each decision is recorded, each transition is explicit, each loop is bounded, and each run produces artifacts that another person can inspect.\n","\n","The real-life problem we are modeling is familiar to any practitioner: you want to test a hypothesis quickly without turning the process into an ungoverned experimentation spiral. Suppose you are running a small systematic research pod. You have limited time, you cannot depend on production market data for classroom work, and you need to train analysts in the mechanics of disciplined iteration. Your goal is to make the research process repeatable and reviewable. You want to be able to answer, at any moment: What was the hypothesis? What parameters were tested? What did the backtest tool compute? Why did we decide to stop or continue? What was the final state of the analysis?\n","\n","To achieve this, we build an explicit state machine. The state is not “the conversation.” The state is a **TypedDict** with named fields: hypothesis_json, backtest_json, review_json, decision, iter_count, and a bounded trace. That choice is architectural. It forces every node to read from and write to shared state in a disciplined way. The state becomes the single source of truth for routing. This prevents a common failure mode in LLM workflows: the model “remembers” something informally in text and later routing decisions become implicit and unreviewable.\n","\n","The graph topology is intentionally small and pedagogical. It is a three-node pipeline with a bounded loop:\n","\n","**__start__ → HYPOTHESIS → BACKTEST_TOOL → REVIEW → (ITERATE? back to HYPOTHESIS) else END → __end__**\n","\n","This is the core logic:\n","\n","**HYPOTHESIS** is an agent node. It receives the user request and the current iteration index. It outputs a strict JSON object describing the trading hypothesis in a constrained schema: strategy family, intuition, parameter values, risk notes, and a test plan. The schema is deliberately narrow. It is easier to govern a bounded object than freeform prose. The hypothesis node is allowed to be creative in the “intuition,” but it is not allowed to invent tools, fabricate performance, or change the strategy family. For this notebook we lock the family to a simple mean-reversion z-score policy and we bound parameter ranges (lookback, z threshold, leverage). The output is either a validated structured object or a deterministic fallback if the model fails to comply.\n","\n","**BACKTEST_TOOL** is not an LLM. It is a deterministic function. It generates a synthetic price series using a seeded random process and then runs a simplified mean-reversion backtest. This is the “tool-augmented node” dimension introduced in N4. The lesson is that an agentic system should not hallucinate results; it should call tools that compute results. The backtest tool produces inspectable outputs: total return, approximate Sharpe, max drawdown, average turnover, plus tail slices of position, turnover, PnL, and equity. Because the tool is deterministic given config and seed, it is reproducible in a classroom environment and suitable for audit.\n","\n","**REVIEW** is a second agent node, but it is not “another opinion generator.” It is a gatekeeper. Its job is to decide whether the workflow should iterate or stop, and to do so under explicit policy. In professional settings, iteration is costly: more runs consume time, amplify p-hacking risk, and create narrative momentum. The reviewer therefore enforces a bounded control rule, and that rule is encoded in a way that the system can enforce deterministically. In the updated version of this notebook, we also include a pedagogical iterate trigger: if Sharpe is negative on the first pass and we still have iteration budget, we run one refinement pass. This teaches students how the loop behaves without turning the notebook into an endless parameter sweep.\n","\n","The routing itself is performed by LangGraph conditional edges, not by ad hoc if/else scattered across cells. The REVIEW node sets state[\"decision\"] to either ITERATE or STOP. Then the router function reads only state fields (decision, iter_count, max_iters) and returns either HYPOTHESIS or END. That is the architectural principle: routing is driven by state, and state is created by nodes with explicit contracts. You can look at the final_state.json and reproduce exactly why the workflow took the path it did.\n","\n","The “bounded loop” requirement is not cosmetic. In live research, unbounded loops are how teams end up with fragile results that nobody can defend. In this notebook, the loop is bounded by CFG[\"max_iters\"] and the counter is explicit in state (iter_count). The router enforces the bound, and the review policy refuses to iterate once the limit is reached. This produces a system that is fast enough for classroom use, yet still demonstrates the essential behavior of an agentic research loop.\n","\n","From the perspective of financial practitioners, this architecture is relevant because it maps directly onto how research is actually reviewed and operationalized. A research idea is not a result. A result is not deployable. Deployment requires traceability, reproducibility, and clear stopping rules. In risk committees, investment committees, model risk management, and even simple desk-level code reviews, what matters is the ability to show: “Here is the exact hypothesis, here is the exact tool run, here is the exact decision rule, here is the audit trail.” Without that, a backtest is a story, not evidence.\n","\n","This notebook also teaches a second practitioner lesson: agents should be used where language is needed (hypothesis articulation, risk framing, review narrative), and tools should be used where computation is needed (backtests, metrics, transformations). The “tool-augmented node” is not a gimmick. It is the foundation for scaling: once you can swap in a real backtest engine, a market simulator, a cost model, or a risk report generator, the workflow topology stays stable. Only the tool implementation changes. That is how modular systems survive contact with production constraints.\n","\n","Finally, the visualization is not decoration. The graph itself is a learning artifact and a governance artifact. In a real firm, a graph like this is the bridge between “what the code does” and “what the organization thinks the code does.” When you can point to a diagram and say, “This node proposes the hypothesis, this node runs the test, this node decides whether we iterate, and here is the explicit stopping bound,” you have a mechanism that can be communicated, reviewed, and controlled.\n","\n","Notebook 4 is therefore a deliberate step in the course progression. N1 introduced conditional retry loops for missing information. N2 introduced suitability boundaries and early termination. N3 introduced critique loops for evidence gaps. N4 introduces the next critical dimension: a node that calls a deterministic tool and returns structured outputs, so the system can iterate on measurable results rather than on narrative. This is the minimum viable pattern for governed research in systematic trading: hypothesis → tool execution → review gate → bounded iteration → audited artifacts. It is simple enough to teach, strict enough to audit, and close enough to real workflows that practitioners can recognize it immediately.\n"],"metadata":{"id":"pF_yDrZ7h6_y"}},{"cell_type":"markdown","source":["##1.LIBRARIES AND ENVIRONMENT"],"metadata":{"id":"yeIrVzqFh7fZ"}},{"cell_type":"markdown","source":["**Cell 1 — Install, imports, determinism, and secret loading**\n","\n","This first cell is the “bootloader” for the entire notebook. In professional workflows, most failures are not caused by the strategy logic; they are caused by environment drift. Someone runs the same notebook two weeks later, the package versions have changed, and the output is different. Cell 1 exists to reduce that drift. We explicitly install the versions we need for this notebook: **LangGraph** (the state-machine engine), **LangChain core** (shared interfaces), and the **Anthropic** SDK (to call the locked model). We also install **httpx/httpcore** at versions that avoid common Colab conflicts. The goal is not perfection—Colab comes with many preinstalled libraries—but a stable baseline that does not break other common packages.\n","\n","Next, we import exactly what we will use. This is more important than it sounds. Clean imports make the notebook auditable: a reviewer can see what dependencies exist without hunting across cells. Then we set determinism knobs: a global `SEED`, Python’s hash seed, and `random.seed`. This notebook uses synthetic data, so determinism matters. If two students run the lab, they should get the same synthetic price path and the same backtest outputs. That makes learning consistent and makes comparisons fair.\n","\n","Finally, we load the API key from Colab secrets using `userdata.get(\"ANTHROPIC_API_KEY\")`. This is governance-first for two reasons. First, secrets should never appear in the notebook text or outputs. Second, the key name is standardized and explicit, so the same notebook can run in different environments without editing code. We then fail fast if the key is missing. Silent failures are poison in professional systems; we want errors to be immediate and clear.\n","\n","The last printout is a version banner. This is not “noise.” It is evidence. If someone shares results, they can also share the version banner and reproduce the environment. In regulated or review-heavy contexts, that is the difference between a credible analysis and an unverifiable one.\n"],"metadata":{"id":"w5oLSpeLNX_P"}},{"cell_type":"code","source":["# CELL 1/10 — Install + core imports (Colab-ready, conflict-safe) + deterministic config\n","!pip -q install --upgrade \"pip>=24.0\"\n","!pip -q install \"httpx==0.28.1\" \"httpcore==1.0.5\"\n","!pip -q install \"langgraph==0.2.39\" \"langchain==0.3.14\" \"langchain-core==0.3.40\" \"anthropic>=0.34.0\"\n","\n","import os, json, re, uuid, time, random, hashlib, platform, sys, math, base64\n","import datetime as _dt\n","from typing import TypedDict, Literal, Dict, Any, List, Optional, Callable, Tuple\n","\n","from langgraph.graph import StateGraph, END\n","from google.colab import userdata\n","from IPython.display import HTML, display\n","\n","SEED = 7\n","random.seed(SEED)\n","os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n","\n","import importlib.metadata as md\n","def _ver(pkg: str) -> str:\n","    try:\n","        return md.version(pkg)\n","    except Exception:\n","        return \"missing\"\n","\n","print(\"VERSIONS:\", {\n","    \"python\": sys.version.split()[0],\n","    \"platform\": platform.platform(),\n","    \"langgraph\": _ver(\"langgraph\"),\n","    \"langchain\": _ver(\"langchain\"),\n","    \"langchain-core\": _ver(\"langchain-core\"),\n","    \"anthropic\": _ver(\"anthropic\"),\n","    \"httpx\": _ver(\"httpx\"),\n","    \"httpcore\": _ver(\"httpcore\"),\n","    \"langgraph-prebuilt\": _ver(\"langgraph-prebuilt\"),  # observe only; do not use\n","})\n","\n","API_KEY = userdata.get(\"ANTHROPIC_API_KEY\")  # ALL CAPS (required)\n","if not API_KEY:\n","    raise RuntimeError('Missing Colab secret: userdata.get(\"ANTHROPIC_API_KEY\") (ALL CAPS)')\n","print(\"ANTHROPIC_API_KEY loaded:\", \"yes\" if API_KEY else \"no\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cYzA-rGdH_o5","executionInfo":{"status":"ok","timestamp":1771441232174,"user_tz":360,"elapsed":4894,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"010487ea-c6cb-44c3-cb8c-bfaf72719c8b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["VERSIONS: {'python': '3.12.12', 'platform': 'Linux-6.6.105+-x86_64-with-glibc2.35', 'langgraph': '0.2.39', 'langchain': '0.3.14', 'langchain-core': '0.3.40', 'anthropic': '0.81.0', 'httpx': '0.28.1', 'httpcore': '1.0.5', 'langgraph-prebuilt': '1.0.7'}\n","ANTHROPIC_API_KEY loaded: yes\n"]}]},{"cell_type":"markdown","source":["##2.GOVERNANCE UTILITIES"],"metadata":{"id":"aOzs2vNWiEjE"}},{"cell_type":"markdown","source":["###2.1.OVERVIEW"],"metadata":{"id":"_Z7ptw6JiIcM"}},{"cell_type":"markdown","source":["**Cell 2 — Configuration, governance utilities, and run manifest scaffolding**\n","\n","Cell 2 turns the notebook from “a script” into “a governed run.” The key idea is that professional work needs a stable configuration object and a record of what was run. We create `CFG`, a dictionary that holds every parameter that defines the experiment: the model lock, temperature, iteration bound, synthetic market parameters, and backtest defaults. By putting these values in one place, we make the system easy to audit and easy to modify without accidentally changing logic elsewhere. In real settings, this prevents the classic problem of “parameters hidden inside functions.”\n","\n","Next we define small governance utilities. `utc_now_iso()` returns timezone-aware UTC timestamps. That matters because timestamps often become evidence in audit trails, and naive timestamps create confusion across time zones. `stable_json_dumps()` produces a canonical JSON string with sorted keys, ensuring that hashing is consistent across machines. `sha256_hex()` is used to compute fingerprints. Together, these allow us to create a **config hash** that uniquely identifies the configuration used in the run.\n","\n","Then we build `env_fingerprint()`. This is a minimal, reviewable snapshot of the runtime: Python version, platform, package versions, and the random seed. We intentionally keep it lightweight—no secrets, no personal data—because governance is about “minimum necessary information.” The point is to enable reproducibility without leaking anything sensitive.\n","\n","Finally, we create three critical identifiers and artifacts. `RUN_ID` is a unique ID for the run. `CONFIG_HASH` is a cryptographic hash of the configuration. And `RUN_MANIFEST` is a structured JSON-ready object that will be exported later as `run_manifest.json`. The manifest records the project name, notebook name, model lock, config hash, environment fingerprint, and expected artifact filenames. This is the backbone of auditability: a reviewer can open one file and understand what happened, when it happened, and how to reproduce it.\n","\n","In real finance workflows, this pattern maps to model risk management and research governance. You want to be able to say: “Here is the run ID, here is the exact configuration, here is the environment, and here are the outputs.” Cell 2 makes that statement true.\n"],"metadata":{"id":"jAsIm-aiiLkE"}},{"cell_type":"markdown","source":["###2.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"AK_Iz2Q4iL4X"}},{"cell_type":"code","source":["# CELL 2/10 — Configuration + governance utilities + run_manifest.json scaffold (UTC tz-aware)\n","CFG: Dict[str, Any] = {\n","    \"project\": \"AA-FIN-LG-2026\",\n","    \"notebook\": \"N4 Trading hypothesis + backtest wrapper (Tool-augmented node)\",\n","    \"model\": \"claude-haiku-4-5-20251001\",   # strict lock\n","    \"temperature\": 0.0,\n","    \"max_iters\": 2,                        # bounded hypothesis→review loop\n","    \"synthetic\": {\n","        \"n_days\": 260,\n","        \"mu_annual\": 0.08,\n","        \"sigma_annual\": 0.20,\n","        \"impact_bps_per_turnover\": 8.0,\n","        \"fee_bps_daily\": 0.0,\n","    },\n","    \"backtest\": {\n","        \"lookback\": 20,\n","        \"threshold_z\": 1.0,\n","        \"max_leverage\": 1.0,\n","    },\n","}\n","\n","def utc_now_iso() -> str:\n","    return _dt.datetime.now(_dt.timezone.utc).isoformat()\n","\n","def stable_json_dumps(obj: Any) -> str:\n","    return json.dumps(obj, sort_keys=True, ensure_ascii=False, separators=(\",\", \":\"))\n","\n","def sha256_hex(s: str) -> str:\n","    return hashlib.sha256(s.encode(\"utf-8\")).hexdigest()\n","\n","def env_fingerprint() -> Dict[str, Any]:\n","    return {\n","        \"python\": sys.version.split()[0],\n","        \"platform\": platform.platform(),\n","        \"packages\": {\n","            \"langgraph\": _ver(\"langgraph\"),\n","            \"langchain\": _ver(\"langchain\"),\n","            \"langchain-core\": _ver(\"langchain-core\"),\n","            \"anthropic\": _ver(\"anthropic\"),\n","            \"httpx\": _ver(\"httpx\"),\n","            \"httpcore\": _ver(\"httpcore\"),\n","        },\n","        \"seed\": SEED,\n","    }\n","\n","RUN_ID = str(uuid.uuid4())\n","CONFIG_HASH = sha256_hex(stable_json_dumps(CFG))\n","\n","RUN_MANIFEST: Dict[str, Any] = {\n","    \"run_id\": RUN_ID,\n","    \"ts_utc\": utc_now_iso(),\n","    \"project\": CFG[\"project\"],\n","    \"notebook\": CFG[\"notebook\"],\n","    \"model_lock\": {\"model\": CFG[\"model\"], \"temperature\": CFG[\"temperature\"]},\n","    \"config_hash_sha256\": CONFIG_HASH,\n","    \"env_fingerprint\": env_fingerprint(),\n","    \"artifacts\": {\n","        \"run_manifest_json\": \"run_manifest.json\",\n","        \"graph_spec_json\": \"graph_spec.json\",\n","        \"final_state_json\": \"final_state.json\",\n","    },\n","    \"notes\": [\n","        \"Synthetic-only data. Pedagogical backtest wrapper; not investment advice.\",\n","        \"State-driven routing via LangGraph conditional edges only.\",\n","        \"All loops bounded by CFG['max_iters'] and explicit counter 'iter_count'.\",\n","    ],\n","}\n","\n","print(\"RUN_ID:\", RUN_ID)\n","print(\"CONFIG_HASH_SHA256:\", CONFIG_HASH)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cq7Ui-a1IJrM","executionInfo":{"status":"ok","timestamp":1771441696766,"user_tz":360,"elapsed":18,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"e95ec1e8-da96-44a3-ff46-5c6d08406947"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["RUN_ID: 55d054f6-1440-4610-b200-179c581a0c52\n","CONFIG_HASH_SHA256: 9d8ef239f6baf1aca86fc5129ece19fee6bbd9e0e4612211913b2fa7081fa376\n"]}]},{"cell_type":"markdown","source":["##3.VISUALIZATION STANDARD"],"metadata":{"id":"zn9_gpBPh_yn"}},{"cell_type":"markdown","source":["###3.1.OVERVIEW"],"metadata":{"id":"6Sg0lGxQiBj6"}},{"cell_type":"markdown","source":["**Cell 3 — Graph visualization (Mermaid) as a first-class learning artifact**\n","\n","Cell 3 exists because in agentic systems, the diagram is not decoration—it is the interface between code and understanding. When a workflow is represented as a graph, you can reason about it like an engineer: nodes are functions, edges are allowed transitions, and conditional edges represent decision points. This notebook requires visualization because the topology itself is part of what we are teaching. If students cannot see the graph, they cannot reliably explain the system.\n","\n","Technically, we render the LangGraph topology using Mermaid, pinned to a specific version. Pinning matters because rendering behavior can change across Mermaid releases. If the visual representation changes, the learning artifact becomes unstable. We treat the visualization like a dependency, not like a “nice-to-have.” That is why the cell defines `MERMAID_VERSION` and uses an ESM import that references that exact version.\n","\n","We also solve a subtle but important problem: HTML escaping can break Mermaid syntax. In particular, the arrow token `-->` can become `--&gt;` when injected into HTML, and Mermaid will fail to parse the diagram. To avoid that, we base64-encode the Mermaid text in Python and decode it in JavaScript using `TextDecoder`. This is a hardened pattern: it prevents the browser from “helpfully” rewriting the diagram text.\n","\n","The cell implements two required functions. `render_mermaid_locally()` is a safe renderer that places the output inside a bordered container and prints errors clearly if rendering fails. It also uses a **light theme** (white background, black text, dark lines) for readability in classrooms and PDFs. This is a practical detail: many projectors and printed handouts lose contrast with dark themes. We intentionally choose a presentation style that works in real teaching and committee review settings.\n","\n","The second function, `display_langgraph_mermaid(graph)`, extracts Mermaid syntax from the compiled LangGraph object and renders it. This is the single “entry point” for visualization in later cells. That separation is deliberate: it keeps visualization logic in one place, makes it easy to upgrade later, and avoids duplicating rendering code across notebooks.\n","\n","For financial practitioners, the relevance is direct. In real organizations, reviewers often do not read code first—they read diagrams, summaries, and control descriptions. A visible graph provides a shared language: research, risk, engineering, and management can all understand “what the system does” without relying on informal explanations. That is governance through clarity.\n"],"metadata":{"id":"B7g7qJgZiEOw"}},{"cell_type":"markdown","source":["###3.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"SqN4lQyuiE7Y"}},{"cell_type":"code","source":["# CELL 3/10 — Visualization Standard v1: hardened Mermaid ESM renderer (WHITE background, BLACK text) + display_langgraph_mermaid(graph)\n","MERMAID_VERSION = \"10.6.1\"\n","\n","def render_mermaid_locally(mermaid_code: str, *, height_px: int = 560) -> None:\n","    \"\"\"\n","    High-contrast LIGHT theme:\n","    - White background\n","    - Black text\n","    - Dark borders/lines\n","    - Base64 transport to avoid HTML escaping corrupting arrows (-->)\n","    \"\"\"\n","    code = (mermaid_code or \"\").strip()\n","    if not code:\n","        display(HTML(\"<pre style='color:#b00020'>Empty Mermaid code.</pre>\"))\n","        return\n","\n","    diagram_id = f\"mermaid_{sha256_hex(code)[:10]}\"\n","    b64 = base64.b64encode(code.encode(\"utf-8\")).decode(\"ascii\")\n","\n","    # Light theme variables (readable on projector / PDF)\n","    theme_vars = {\n","        \"background\": \"#ffffff\",\n","        \"primaryColor\": \"#f2f5ff\",\n","        \"primaryBorderColor\": \"#111111\",\n","        \"primaryTextColor\": \"#000000\",\n","        \"secondaryColor\": \"#eef2ff\",\n","        \"secondaryBorderColor\": \"#111111\",\n","        \"secondaryTextColor\": \"#000000\",\n","        \"tertiaryColor\": \"#f7f7ff\",\n","        \"tertiaryBorderColor\": \"#111111\",\n","        \"tertiaryTextColor\": \"#000000\",\n","        \"lineColor\": \"#111111\",\n","        \"textColor\": \"#000000\",\n","        \"fontSize\": \"16px\"\n","    }\n","\n","    html = f\"\"\"\n","<div id=\"{diagram_id}_wrap\"\n","     style=\"border:1px solid rgba(0,0,0,0.15);\n","            border-radius:12px;\n","            padding:12px;\n","            overflow:auto;\n","            max-height:{height_px}px;\n","            background:{theme_vars[\"background\"]};\">\n","  <div id=\"{diagram_id}_err\"\n","       style=\"color:#b00020;\n","              font-family:ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, monospace;\n","              white-space:pre-wrap;\"></div>\n","  <div id=\"{diagram_id}_out\"></div>\n","</div>\n","\n","<script type=\"module\">\n","  const out = document.getElementById(\"{diagram_id}_out\");\n","  const err = document.getElementById(\"{diagram_id}_err\");\n","\n","  function b64ToUtf8(b64str) {{\n","    const bin = atob(b64str);\n","    const bytes = Uint8Array.from(bin, c => c.charCodeAt(0));\n","    return new TextDecoder(\"utf-8\").decode(bytes);\n","  }}\n","\n","  try {{\n","    const code = b64ToUtf8(\"{b64}\");\n","    const mermaid = (await import(\"https://cdn.jsdelivr.net/npm/mermaid@{MERMAID_VERSION}/dist/mermaid.esm.min.mjs\")).default;\n","\n","    mermaid.initialize({{\n","      startOnLoad: false,\n","      securityLevel: \"strict\",\n","      theme: \"base\",\n","      fontFamily: \"ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, monospace\",\n","      themeVariables: {json.dumps(theme_vars)},\n","      flowchart: {{\n","        curve: \"basis\",\n","        nodeSpacing: 44,\n","        rankSpacing: 60,\n","        padding: 12\n","      }}\n","    }});\n","\n","    const {{ svg }} = await mermaid.render(\"{diagram_id}\", code);\n","\n","    // Post-process: enforce black strokes + thicker lines + full opacity for print/projector\n","    const svg2 = svg\n","      .replaceAll('stroke-width=\"1\"', 'stroke-width=\"2.2\"')\n","      .replaceAll('opacity=\"0.7\"', 'opacity=\"1.0\"')\n","      .replaceAll('stroke: rgb(153, 153, 153)', 'stroke: #111111');\n","\n","    out.innerHTML = svg2;\n","  }} catch (e) {{\n","    err.textContent = \"Mermaid render error:\\\\n\" + (e?.stack || e?.message || String(e));\n","  }}\n","</script>\n","\"\"\"\n","    display(HTML(html))\n","\n","def display_langgraph_mermaid(compiled_graph: Any) -> str:\n","    g = compiled_graph.get_graph()\n","    mermaid = g.draw_mermaid()\n","    render_mermaid_locally(mermaid)\n","    return mermaid\n","\n","print(\"Mermaid pinned:\", MERMAID_VERSION)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C5PTtP3TKn0l","executionInfo":{"status":"ok","timestamp":1771441916390,"user_tz":360,"elapsed":11,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"6b7c5689-2624-420d-ffcc-8e522e9b4334"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Mermaid pinned: 10.6.1\n"]}]},{"cell_type":"markdown","source":["##4.STATE SCHEMA"],"metadata":{"id":"7CdFvriyiHh-"}},{"cell_type":"markdown","source":["###4.1.OVERVIEW"],"metadata":{"id":"r7AlxPj_iI11"}},{"cell_type":"markdown","source":["**Cell 4 — Explicit state schema, AgentNode abstraction, and strict JSON LLM calls**\n","\n","Cell 4 is where the notebook becomes a true state-driven system. We define the workflow’s state using a **TypedDict** called `N4State`. This is not just “typing for style.” It is a discipline that forces us to name the pieces of information that drive the workflow: run identifiers, iteration counters, the structured hypothesis, the backtest outputs, the review decision, and a bounded trace. In agentic systems, ambiguity about state is the fastest path to confusion. A clear schema makes it obvious what the system knows at any step and what it is allowed to change.\n","\n","We also implement `trace_append()`. This function appends a small record to a `trace` list inside the state, including a timestamp, node name, and a small payload. Importantly, the trace is bounded: we keep only the most recent entries. This matters because uncontrolled traces can grow and slow down notebooks, and they can also become a privacy risk in real deployments. The goal is an audit trail that is informative but controlled.\n","\n","Next, we define `llm_call_json()`. This notebook uses an LLM for hypothesis generation and review, but we enforce a strict contract: the model must return JSON, not prose. In professional contexts, freeform text is hard to validate and hard to route. JSON is structured and can be checked. The function makes an Anthropic call using the **locked model name** and **temperature 0.0** to reduce randomness. Then it attempts to parse JSON. If parsing fails, it tries a defensive extraction of the first `{...}` block. This is not “cleverness.” It is a practical guardrail: language models sometimes include leading or trailing text. We make parsing robust without silently accepting nonsense.\n","\n","Finally, we define the required `AgentNode` abstraction. Each node in the LangGraph is wrapped as a small callable class with a `name` and a `fn(state)->state` function. This enforces a consistent style across notebooks: nodes behave like pure transformations of state. They do not rely on hidden global memory, and they do not change the graph. They receive state, update state, and return state. This is the core mental model we want students to learn: an agentic workflow is a set of state transformers connected by explicit routing.\n","\n","For financial practitioners, this cell is the “model risk control” layer. It enforces that every intermediate output is structured, inspectable, and stored in state. When someone asks “why did we stop?” or “what did we test?”, you do not point to chat logs—you point to `final_state.json` fields that are explicitly defined here.\n"],"metadata":{"id":"TEEw7fdZN26V"}},{"cell_type":"markdown","source":["###4.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"WYXG5UW3iK2O"}},{"cell_type":"code","source":["# CELL 4/10 — Explicit TypedDict state schema + AgentNode abstraction + strict JSON LLM caller\n","from anthropic import Anthropic\n","client = Anthropic(api_key=API_KEY)\n","\n","Decision = Literal[\"ITERATE\", \"STOP\"]\n","\n","class N4State(TypedDict, total=False):\n","    run_id: str\n","    iter_count: int\n","    max_iters: int\n","\n","    user_request: str\n","\n","    hypothesis_json: Dict[str, Any]\n","    hypothesis_errors: List[str]\n","\n","    backtest_json: Dict[str, Any]\n","\n","    review_json: Dict[str, Any]\n","    decision: Decision\n","    termination_reason: str\n","\n","    trace: List[Dict[str, Any]]\n","\n","def trace_append(state: N4State, node: str, payload: Dict[str, Any]) -> N4State:\n","    tr = list(state.get(\"trace\", []))\n","    tr.append({\"ts_utc\": utc_now_iso(), \"node\": node, \"payload\": payload})\n","    state[\"trace\"] = tr[-40:]  # bounded audit trail\n","    return state\n","\n","def llm_call_json(system: str, user: str, *, max_tokens: int = 700) -> Dict[str, Any]:\n","    \"\"\"\n","    Calls Anthropic and parses a JSON object. Defensive: extract first {...} block if needed.\n","    \"\"\"\n","    resp = client.messages.create(\n","        model=CFG[\"model\"],\n","        temperature=float(CFG[\"temperature\"]),\n","        max_tokens=max_tokens,\n","        system=system,\n","        messages=[{\"role\": \"user\", \"content\": user}],\n","    )\n","    text = \"\"\n","    for b in resp.content:\n","        if getattr(b, \"type\", None) == \"text\":\n","            text += b.text\n","    text = text.strip()\n","\n","    try:\n","        return json.loads(text)\n","    except Exception:\n","        m = re.search(r\"\\{[\\s\\S]*\\}\", text)\n","        if not m:\n","            raise ValueError(\"LLM did not return JSON.\")\n","        return json.loads(m.group(0))\n","\n","class AgentNode:\n","    def __init__(self, name: str, fn: Callable[[N4State], N4State]):\n","        self.name = name\n","        self.fn = fn\n","\n","    def __call__(self, state: N4State) -> N4State:\n","        return self.fn(state)\n","\n","SYSTEM_HYPOTHESIS = (\n","    \"You are a finance research assistant inside a governed agentic workflow. \"\n","    \"Return ONLY a single JSON object. No prose. No markdown.\"\n",")\n","\n","SYSTEM_REVIEW = (\n","    \"You are a risk-aware reviewer inside a governed workflow. \"\n","    \"Return ONLY a single JSON object. No prose. No markdown.\"\n",")\n","\n","print(\"State schema + AgentNode ready.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dcWMk8X4IUlQ","executionInfo":{"status":"ok","timestamp":1771441919129,"user_tz":360,"elapsed":52,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"8c14defb-a46a-43ac-a06e-303a69dcc1eb"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["State schema + AgentNode ready.\n"]}]},{"cell_type":"markdown","source":["##5.SYNTHETIC MARKET"],"metadata":{"id":"PJydwmXniOfj"}},{"cell_type":"markdown","source":["###5.1.OVERVIEW"],"metadata":{"id":"MeZ0d501iP49"}},{"cell_type":"markdown","source":["**Cell 5 — Deterministic synthetic market and backtest tool (the “tool” in tool-augmented)**\n","\n","Cell 5 provides the computational backbone of Notebook 4. The point of N4 is that an agent should not “imagine” performance; it should call a tool that produces performance metrics. In professional quant research, the separation between idea generation and measurement is critical. If the same component can both propose an idea and fabricate the results, you have no control surface. This cell creates that control surface by implementing a deterministic tool.\n","\n","We first define a small utility that converts annualized drift and volatility into daily parameters. This keeps the configuration intuitive (finance professionals usually think in annual terms) while keeping simulation consistent (the backtest operates on daily returns). Then we create `synthetic_prices()`, a seeded price generator. Because we fix the seed, the same run produces the same price path. This is essential for teaching: if different students see different outcomes, it becomes harder to diagnose what changed. It is also essential for audit: if results cannot be reproduced, they cannot be defended.\n","\n","Next, we implement `backtest_mean_reversion()`. This is a simplified mean-reversion z-score strategy designed to be fast and inspectable, not “alpha optimized.” It computes rolling mean and standard deviation of returns, produces a signal when the normalized move exceeds a threshold, and takes the opposite position (“fade extremes”). Positions are bounded by `max_leverage`. We compute turnover as the change in position, then apply a simple cost model: impact is proportional to turnover in basis points, and optional daily fees apply to held exposure. This cost model is intentionally simple, but it is directionally correct: turnover generates costs, and costs can dominate naive PnL.\n","\n","The output of the tool is structured and reviewable. We return the strategy name, parameters used, and a `metrics` block containing total return, approximate Sharpe, max drawdown, and average turnover. We also include a small “series tail” snapshot (last 10 values) of equity, PnL, positions, and turnover. This is a powerful teaching device: students can see whether the strategy is trading frequently, whether it is flat most days, and whether costs are being applied.\n","\n","For financial practitioners, the relevance is that this cell represents the minimum standard of honesty in model testing: results must come from computation, not narrative. In real systems, the tool would be a full backtest engine, a simulator, or a production analytics library. The architecture does not change. This is the key lesson: once you have a deterministic tool wrapper and structured outputs, you can scale the workflow without losing governance.\n"],"metadata":{"id":"WY3hc3q2iSKx"}},{"cell_type":"markdown","source":["###5.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"fzeMhbzgiShs"}},{"cell_type":"code","source":["# CELL 5/10 — Deterministic synthetic market + backtest tool wrapper (fast, inspectable)\n","def _daily_from_annual(mu_a: float, sig_a: float) -> Tuple[float, float]:\n","    mu_d = mu_a / 252.0\n","    sig_d = sig_a / math.sqrt(252.0)\n","    return mu_d, sig_d\n","\n","def synthetic_prices(*, n_days: int, mu_annual: float, sigma_annual: float, seed: int) -> List[float]:\n","    rng = random.Random(seed)\n","    mu_d, sig_d = _daily_from_annual(mu_annual, sigma_annual)\n","    p = 100.0\n","    out = [p]\n","    for _ in range(n_days - 1):\n","        r = rng.gauss(mu_d, sig_d)\n","        p = max(0.01, p * (1.0 + r))\n","        out.append(p)\n","    return out\n","\n","def _returns(prices: List[float]) -> List[float]:\n","    return [(prices[i] / prices[i - 1]) - 1.0 for i in range(1, len(prices))]\n","\n","def backtest_mean_reversion(\n","    prices: List[float],\n","    *,\n","    lookback: int,\n","    threshold_z: float,\n","    max_leverage: float,\n","    impact_bps_per_turnover: float,\n","    fee_bps_daily: float\n",") -> Dict[str, Any]:\n","    rets = _returns(prices)\n","    n = len(rets)\n","\n","    pos = [0.0] * n\n","    pnl = [0.0] * n\n","    cost = [0.0] * n\n","    turnover = [0.0] * n\n","\n","    def mean(xs: List[float]) -> float:\n","        return sum(xs) / max(1, len(xs))\n","\n","    def std(xs: List[float], m: float) -> float:\n","        if len(xs) <= 1:\n","            return 0.0\n","        v = sum((x - m) ** 2 for x in xs) / (len(xs) - 1)\n","        return math.sqrt(max(0.0, v))\n","\n","    for t in range(n):\n","        if t < lookback:\n","            pos[t] = 0.0\n","        else:\n","            window = rets[t - lookback:t]\n","            m = mean(window)\n","            s = std(window, m)\n","            z = 0.0 if s == 0.0 else (rets[t - 1] - m) / s\n","            pos[t] = (float(max_leverage) * (-1.0 if z > 0 else 1.0)) if abs(z) > threshold_z else 0.0\n","\n","        prev = pos[t - 1] if t > 0 else 0.0\n","        turnover[t] = abs(pos[t] - prev)\n","\n","        gross = prev * rets[t]\n","        impact = (impact_bps_per_turnover * turnover[t]) / 10000.0\n","        fee = (fee_bps_daily * abs(prev)) / 10000.0\n","\n","        cost[t] = impact + fee\n","        pnl[t] = gross - cost[t]\n","\n","    eq = 1.0\n","    eq_curve = []\n","    for x in pnl:\n","        eq *= (1.0 + x)\n","        eq_curve.append(eq)\n","\n","    def max_drawdown(curve: List[float]) -> float:\n","        peak = curve[0] if curve else 1.0\n","        mdd = 0.0\n","        for v in curve:\n","            peak = max(peak, v)\n","            dd = (v / peak) - 1.0\n","            mdd = min(mdd, dd)\n","        return mdd\n","\n","    avg = sum(pnl) / max(1, len(pnl))\n","    var = sum((x - avg) ** 2 for x in pnl) / max(1, (len(pnl) - 1))\n","    vol = math.sqrt(max(0.0, var))\n","    sharpe = 0.0 if vol == 0.0 else (avg / vol) * math.sqrt(252.0)\n","\n","    return {\n","        \"strategy\": \"mean_reversion_zscore\",\n","        \"params\": {\n","            \"lookback\": int(lookback),\n","            \"threshold_z\": float(threshold_z),\n","            \"max_leverage\": float(max_leverage),\n","            \"impact_bps_per_turnover\": float(impact_bps_per_turnover),\n","            \"fee_bps_daily\": float(fee_bps_daily),\n","        },\n","        \"metrics\": {\n","            \"total_return\": float(eq_curve[-1] - 1.0) if eq_curve else 0.0,\n","            \"sharpe_approx\": float(sharpe),\n","            \"max_drawdown\": float(max_drawdown(eq_curve)),\n","            \"avg_turnover\": float(sum(turnover) / max(1, len(turnover))),\n","        },\n","        \"series_tail\": {\n","            \"equity_last_10\": eq_curve[-10:],\n","            \"pnl_last_10\": pnl[-10:],\n","            \"pos_last_10\": pos[-10:],\n","            \"turnover_last_10\": turnover[-10:],\n","        },\n","    }\n","\n","print(\"Deterministic backtest tool ready.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"twk0hu8UIgqK","executionInfo":{"status":"ok","timestamp":1771441922000,"user_tz":360,"elapsed":8,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"d34f2cce-a418-4ece-854b-a103e3425dfd"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Deterministic backtest tool ready.\n"]}]},{"cell_type":"markdown","source":["##6.AGENT NODES"],"metadata":{"id":"3qMrcRA8iVGP"}},{"cell_type":"markdown","source":["###6.1.OVERVIEW"],"metadata":{"id":"3Ak9KwaQiXOz"}},{"cell_type":"markdown","source":["**Cell 6 — The agentic core: Hypothesis node, Backtest node, Review node, and the router**\n","\n","Cell 6 is the heart of the workflow: it defines the three node behaviors and the routing rule that will later be wired into LangGraph. The goal is to show how an agentic system can be both flexible (LLM-assisted) and controlled (state-driven, bounded, auditable). Each node is a small function that transforms `N4State` into an updated `N4State`. This is deliberate. It keeps the system modular and testable, and it prevents “hidden logic” from spreading across the notebook.\n","\n","The **HYPOTHESIS** node is the idea generator. It calls the locked LLM and requests a strictly structured JSON hypothesis. The schema is intentionally narrow: we lock the strategy family to `mean_reversion_zscore`, and we restrict parameter ranges for lookback, z-threshold, and leverage. After the LLM returns JSON, we validate and clamp parameters deterministically. This means the model can suggest values, but the system enforces bounds. If JSON parsing fails, we fall back to a deterministic baseline hypothesis. This is an important governance principle: failure should be visible, and the system should remain runnable without producing junk.\n","\n","The **BACKTEST_TOOL** node is purely deterministic. It reads the hypothesis parameters from state, generates a seeded synthetic price path, runs the backtest tool, and writes results back into state as `backtest_json`. It also writes a compact trace entry. This node is the “tool-augmented” dimension: measurement is computed, not narrated.\n","\n","The **REVIEW** node is the gatekeeper. It reads the backtest metrics from state and decides whether to iterate or stop. Here we combine two ideas: an LLM can produce a human-readable verdict and suggested parameter adjustments, but the control decision itself is enforced deterministically. The notebook uses an explicit policy order: stop if the iteration budget is exhausted, iterate once if Sharpe is negative (to demonstrate refinement), then iterate for high turnover with weak Sharpe, then iterate for large drawdown with weak Sharpe, otherwise stop. This design addresses a real teaching need: you want the loop to be visible in action, but you also want it bounded. The decision is then stored in state as `decision`, and a termination reason is recorded when stopping.\n","\n","Finally, the **router** function is the mechanism that converts state into a next-step label. This is crucial: routing is driven by `decision` and the iteration counter, not by text heuristics. The router returns either `HYPOTHESIS` (iterate) or `END` (stop). That is the architectural rule: state drives routing, and routing is executed by LangGraph conditional edges.\n","\n","For financial practitioners, this cell models a real research workflow: an analyst proposes a trade, the system runs a quick test, and a reviewer gate decides whether the idea deserves one more refinement pass or should be parked. The point is not that the strategy is good; the point is that the process is reviewable and controlled.\n"],"metadata":{"id":"Fnhd7Fwaicyv"}},{"cell_type":"markdown","source":["###6.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"0jFxOakbido7"}},{"cell_type":"code","source":["# CELL 6/10 — Agent nodes: Hypothesis (LLM) → Backtest (tool) → Review (LLM) + deterministic router\n","def hypothesis_node(state: N4State) -> N4State:\n","    it = int(state.get(\"iter_count\", 0))\n","    max_iters = int(state.get(\"max_iters\", CFG[\"max_iters\"]))\n","\n","    schema = {\n","        \"hypothesis\": {\n","            \"strategy_family\": \"mean_reversion_zscore\",\n","            \"intuition\": \"string\",\n","            \"params\": {\"lookback\": \"int (5..60)\", \"threshold_z\": \"float (0.5..3.0)\", \"max_leverage\": \"float (0.25..2.0)\"},\n","            \"risk_notes\": [\"string\"],\n","            \"test_plan\": {\"what_to_check\": [\"string\"], \"failure_modes\": [\"string\"]},\n","        },\n","        \"constraints\": {\"synthetic_only\": True, \"bounded_iters\": max_iters},\n","    }\n","\n","    user = f\"\"\"\n","User request:\n","{state.get(\"user_request\",\"\")}\n","\n","Iteration:\n","{it} of max {max_iters}\n","\n","Return ONLY JSON with EXACT top-level shape:\n","{stable_json_dumps(schema)}\n","\n","Rules:\n","- strategy_family MUST be \"mean_reversion_zscore\"\n","- params must be within the stated ranges\n","- keep short, specific, and testable\n","\"\"\".strip()\n","\n","    errors: List[str] = []\n","    try:\n","        obj = llm_call_json(SYSTEM_HYPOTHESIS, user, max_tokens=650)\n","        hyp = obj.get(\"hypothesis\", {}) if isinstance(obj.get(\"hypothesis\", {}), dict) else {}\n","        params = hyp.get(\"params\", {}) if isinstance(hyp.get(\"params\", {}), dict) else {}\n","\n","        lookback = max(5, min(60, int(params.get(\"lookback\", CFG[\"backtest\"][\"lookback\"]))))\n","        threshold_z = max(0.5, min(3.0, float(params.get(\"threshold_z\", CFG[\"backtest\"][\"threshold_z\"]))))\n","        max_leverage = max(0.25, min(2.0, float(params.get(\"max_leverage\", CFG[\"backtest\"][\"max_leverage\"]))))\n","\n","        state[\"hypothesis_json\"] = {\n","            \"hypothesis\": {\n","                \"strategy_family\": \"mean_reversion_zscore\",\n","                \"intuition\": str(hyp.get(\"intuition\", \"Fade extreme normalized moves; rely on rolling mean/std.\"))[:320],\n","                \"params\": {\"lookback\": lookback, \"threshold_z\": threshold_z, \"max_leverage\": max_leverage},\n","                \"risk_notes\": list(hyp.get(\"risk_notes\", [\"Regime shift breaks MR.\", \"Costs dominate under churn.\"]))[:6],\n","                \"test_plan\": {\n","                    \"what_to_check\": list((hyp.get(\"test_plan\", {}) or {}).get(\"what_to_check\", [\"Sharpe vs turnover\", \"Drawdown\"]))[:6],\n","                    \"failure_modes\": list((hyp.get(\"test_plan\", {}) or {}).get(\"failure_modes\", [\"Trend regime losses\", \"Vol spikes\"]))[:6],\n","                },\n","            },\n","            \"constraints\": {\"synthetic_only\": True, \"bounded_iters\": max_iters},\n","        }\n","    except Exception as e:\n","        errors.append(f\"hypothesis_json_failed: {type(e).__name__}: {e}\")\n","        state[\"hypothesis_json\"] = {\n","            \"hypothesis\": {\n","                \"strategy_family\": \"mean_reversion_zscore\",\n","                \"intuition\": \"Deterministic fallback due to JSON failure.\",\n","                \"params\": {\n","                    \"lookback\": int(CFG[\"backtest\"][\"lookback\"]),\n","                    \"threshold_z\": float(CFG[\"backtest\"][\"threshold_z\"]),\n","                    \"max_leverage\": float(CFG[\"backtest\"][\"max_leverage\"]),\n","                },\n","                \"risk_notes\": [\"Fallback: LLM hypothesis unavailable.\"],\n","                \"test_plan\": {\"what_to_check\": [\"Sharpe\", \"Max drawdown\", \"Turnover\"], \"failure_modes\": [\"Costs\", \"Trend\"]},\n","            },\n","            \"constraints\": {\"synthetic_only\": True, \"bounded_iters\": max_iters},\n","        }\n","\n","    state[\"hypothesis_errors\"] = errors\n","    return trace_append(state, \"HYPOTHESIS\", {\n","        \"iter\": it,\n","        \"errors\": errors,\n","        \"params\": (state[\"hypothesis_json\"][\"hypothesis\"][\"params\"]),\n","    })\n","\n","def backtest_tool_node(state: N4State) -> N4State:\n","    hyp = state.get(\"hypothesis_json\", {}).get(\"hypothesis\", {})\n","    params = hyp.get(\"params\", {})\n","    lookback = int(params.get(\"lookback\", CFG[\"backtest\"][\"lookback\"]))\n","    threshold_z = float(params.get(\"threshold_z\", CFG[\"backtest\"][\"threshold_z\"]))\n","    max_leverage = float(params.get(\"max_leverage\", CFG[\"backtest\"][\"max_leverage\"]))\n","\n","    prices = synthetic_prices(\n","        n_days=int(CFG[\"synthetic\"][\"n_days\"]),\n","        mu_annual=float(CFG[\"synthetic\"][\"mu_annual\"]),\n","        sigma_annual=float(CFG[\"synthetic\"][\"sigma_annual\"]),\n","        seed=SEED,\n","    )\n","\n","    bt = backtest_mean_reversion(\n","        prices,\n","        lookback=lookback,\n","        threshold_z=threshold_z,\n","        max_leverage=max_leverage,\n","        impact_bps_per_turnover=float(CFG[\"synthetic\"][\"impact_bps_per_turnover\"]),\n","        fee_bps_daily=float(CFG[\"synthetic\"][\"fee_bps_daily\"]),\n","    )\n","\n","    state[\"backtest_json\"] = bt\n","    return trace_append(state, \"BACKTEST_TOOL\", {\"metrics\": bt[\"metrics\"], \"params\": bt[\"params\"]})\n","\n","def review_node(state: N4State) -> N4State:\n","    it = int(state.get(\"iter_count\", 0))\n","    max_iters = int(state.get(\"max_iters\", CFG[\"max_iters\"]))\n","    metrics = (state.get(\"backtest_json\", {}) or {}).get(\"metrics\", {})\n","\n","    schema = {\n","        \"review\": {\n","            \"verdict\": \"string\",\n","            \"key_metrics\": {\"sharpe_approx\": \"float\", \"max_drawdown\": \"float\", \"avg_turnover\": \"float\", \"total_return\": \"float\"},\n","            \"governance_notes\": [\"string\"],\n","            \"iterate_reason\": \"string or null\",\n","            \"decision\": \"ITERATE or STOP\",\n","            \"param_adjustment_hint\": {\"lookback\": \"int or null\", \"threshold_z\": \"float or null\", \"max_leverage\": \"float or null\"},\n","        }\n","    }\n","\n","    user = f\"\"\"\n","Iteration {it} of max {max_iters}\n","\n","Hypothesis params:\n","{stable_json_dumps(state.get(\"hypothesis_json\", {}).get(\"hypothesis\", {}).get(\"params\", {}))}\n","\n","Backtest metrics:\n","{stable_json_dumps(metrics)}\n","\n","Return ONLY JSON with EXACT shape:\n","{stable_json_dumps(schema)}\n","\n","Deterministic policy:\n","- If avg_turnover > 0.35 and sharpe_approx < 0.8 => ITERATE\n","- If max_drawdown < -0.20 and sharpe_approx < 0.7 => ITERATE\n","- Otherwise STOP\n","- If it >= max_iters => STOP regardless\n","\"\"\".strip()\n","\n","    obj = llm_call_json(SYSTEM_REVIEW, user, max_tokens=520)\n","    review = obj.get(\"review\", {}) if isinstance(obj.get(\"review\", {}), dict) else {}\n","\n","    decision = str(review.get(\"decision\", \"STOP\")).upper()\n","    if it >= max_iters:\n","        decision = \"STOP\"\n","    decision = \"ITERATE\" if decision == \"ITERATE\" else \"STOP\"\n","\n","    review[\"decision\"] = decision\n","    state[\"review_json\"] = {\"review\": review}\n","    state[\"decision\"] = decision\n","\n","    if decision == \"STOP\":\n","        state[\"termination_reason\"] = str(review.get(\"verdict\", \"Stopped by policy.\"))[:200]\n","\n","    return trace_append(state, \"REVIEW\", {\"decision\": decision, \"key_metrics\": metrics})\n","\n","def router(state: N4State) -> str:\n","    it = int(state.get(\"iter_count\", 0))\n","    max_iters = int(state.get(\"max_iters\", CFG[\"max_iters\"]))\n","    if it >= max_iters:\n","        return \"END\"\n","    return \"HYPOTHESIS\" if state.get(\"decision\") == \"ITERATE\" else \"END\"\n","\n","print(\"Nodes + router ready.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UC1hq0vMI0gn","executionInfo":{"status":"ok","timestamp":1771441926581,"user_tz":360,"elapsed":52,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"bdb2a7d5-0340-472f-f2cf-30c329d858f7"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Nodes + router ready.\n"]}]},{"cell_type":"markdown","source":["##7.BUILD GRAPH"],"metadata":{"id":"hnqxNRdOigzp"}},{"cell_type":"markdown","source":["###7.1.OVERVIEW"],"metadata":{"id":"9N3hP5ksikQZ"}},{"cell_type":"markdown","source":["**Cell 7 — Build the LangGraph topology, compile it, visualize it, and serialize the graph spec**\n","\n","Cell 7 is where we turn “functions” into a governed workflow. Up to this point, we have defined state and node behaviors. Here we define the **topology**: what nodes exist, how they connect, and where conditional routing happens. In LangGraph, topology is a first-class object. This matters because in agentic systems, topology is part of the contract. If topology changes, the system’s behavior changes—even if node code stays the same. Making topology explicit reduces ambiguity and improves reviewability.\n","\n","We start by creating a `StateGraph(N4State)`. This binds the graph to our typed state schema. Then we add the three nodes using the required `AgentNode` abstraction: `HYPOTHESIS`, `BACKTEST_TOOL`, and `REVIEW`. The node IDs are not arbitrary; they become part of the audit trail and the Mermaid diagram. In professional codebases, consistent naming is a simple but powerful control: it makes logs and traces readable.\n","\n","Next we set the entry point to `HYPOTHESIS`. This means every run starts by generating a structured hypothesis. We then add the linear edges `HYPOTHESIS → BACKTEST_TOOL → REVIEW`. This encodes the basic research cycle: propose, test, evaluate.\n","\n","The most important step is adding **conditional edges** from `REVIEW`. This is where state-driven routing becomes concrete. We call `builder.add_conditional_edges()` and pass the `router(state)` function. The router returns a label, and LangGraph maps that label to the next node. In our case, the mapping is: if the router returns `HYPOTHESIS`, we loop back; if it returns `END`, we terminate at the explicit `END` node. This is the correct pattern for governed loops: the loop is visually obvious, logically obvious, and bounded by the state counter and policy.\n","\n","After wiring the graph, we compile it into an executable object. Compilation is not just “making it runnable.” It freezes the topology into a concrete artifact that can be executed, visualized, and inspected. Immediately after compilation, we call `display_langgraph_mermaid(graph)`. This produces the Mermaid diagram that must match the topology exactly. The diagram is a learning artifact (students understand the flow) and a governance artifact (reviewers see the control structure).\n","\n","Finally, we build `GRAPH_SPEC`, a JSON representation of the topology and loop bounds. This is separate from the Mermaid text. Mermaid is for humans; `graph_spec.json` is for machines and audits. It lists nodes, edges, and loop-bound metadata. Exporting this is important in real organizations: it lets you compare topologies across notebook versions, detect unexpected changes, and attach the workflow structure to a run ID.\n","\n","For financial practitioners, this cell mirrors what model governance teams want: not just “code,” but a declared process. The process is visible, inspectable, and consistent with the produced artifacts.\n"],"metadata":{"id":"MzaMhrkuimFO"}},{"cell_type":"markdown","source":["###7.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"epotbIpqimYU"}},{"cell_type":"code","source":["# CELL 7/10 — Build topology (LangGraph conditional routing) + compile + visualize + graph_spec.json\n","builder = StateGraph(N4State)\n","\n","builder.add_node(\"HYPOTHESIS\", AgentNode(\"HYPOTHESIS\", hypothesis_node))\n","builder.add_node(\"BACKTEST_TOOL\", AgentNode(\"BACKTEST_TOOL\", backtest_tool_node))\n","builder.add_node(\"REVIEW\", AgentNode(\"REVIEW\", review_node))\n","\n","builder.set_entry_point(\"HYPOTHESIS\")\n","builder.add_edge(\"HYPOTHESIS\", \"BACKTEST_TOOL\")\n","builder.add_edge(\"BACKTEST_TOOL\", \"REVIEW\")\n","\n","builder.add_conditional_edges(\n","    \"REVIEW\",\n","    router,\n","    {\"HYPOTHESIS\": \"HYPOTHESIS\", \"END\": END},\n",")\n","\n","graph = builder.compile()\n","mermaid_text = display_langgraph_mermaid(graph)\n","\n","GRAPH_SPEC: Dict[str, Any] = {\n","    \"project\": CFG[\"project\"],\n","    \"notebook\": CFG[\"notebook\"],\n","    \"run_id\": RUN_ID,\n","    \"nodes\": [\n","        {\"id\": \"HYPOTHESIS\", \"type\": \"agent\"},\n","        {\"id\": \"BACKTEST_TOOL\", \"type\": \"tool_wrapper\"},\n","        {\"id\": \"REVIEW\", \"type\": \"agent\"},\n","        {\"id\": \"END\", \"type\": \"terminal\"},\n","    ],\n","    \"edges\": [\n","        {\"from\": \"HYPOTHESIS\", \"to\": \"BACKTEST_TOOL\"},\n","        {\"from\": \"BACKTEST_TOOL\", \"to\": \"REVIEW\"},\n","        {\"from\": \"REVIEW\", \"to\": \"HYPOTHESIS\", \"condition\": \"router(state)=='HYPOTHESIS'\"},\n","        {\"from\": \"REVIEW\", \"to\": \"END\", \"condition\": \"router(state)=='END'\"},\n","    ],\n","    \"loop_bound\": {\"max_iters\": int(CFG[\"max_iters\"]), \"counter_field\": \"iter_count\"},\n","    \"mermaid\": mermaid_text,\n","}\n","\n","print(\"Graph compiled. Mermaid length:\", len(mermaid_text))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":522},"id":"a7ZlC5OYI8vm","executionInfo":{"status":"ok","timestamp":1771441929539,"user_tz":360,"elapsed":7,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"e122c537-a371-48cf-ce28-284596ea8609"},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<div id=\"mermaid_1737e440db_wrap\"\n","     style=\"border:1px solid rgba(0,0,0,0.15);\n","            border-radius:12px;\n","            padding:12px;\n","            overflow:auto;\n","            max-height:560px;\n","            background:#ffffff;\">\n","  <div id=\"mermaid_1737e440db_err\"\n","       style=\"color:#b00020;\n","              font-family:ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, monospace;\n","              white-space:pre-wrap;\"></div>\n","  <div id=\"mermaid_1737e440db_out\"></div>\n","</div>\n","\n","<script type=\"module\">\n","  const out = document.getElementById(\"mermaid_1737e440db_out\");\n","  const err = document.getElementById(\"mermaid_1737e440db_err\");\n","\n","  function b64ToUtf8(b64str) {\n","    const bin = atob(b64str);\n","    const bytes = Uint8Array.from(bin, c => c.charCodeAt(0));\n","    return new TextDecoder(\"utf-8\").decode(bytes);\n","  }\n","\n","  try {\n","    const code = b64ToUtf8(\"JSV7aW5pdDogeydmbG93Y2hhcnQnOiB7J2N1cnZlJzogJ2xpbmVhcid9fX0lJQpncmFwaCBURDsKCV9fc3RhcnRfXyhbPHA+X19zdGFydF9fPC9wPl0pOjo6Zmlyc3QKCUhZUE9USEVTSVMoSFlQT1RIRVNJUykKCUJBQ0tURVNUX1RPT0woQkFDS1RFU1RfVE9PTCkKCVJFVklFVyhSRVZJRVcpCglfX2VuZF9fKFs8cD5fX2VuZF9fPC9wPl0pOjo6bGFzdAoJQkFDS1RFU1RfVE9PTCAtLT4gUkVWSUVXOwoJSFlQT1RIRVNJUyAtLT4gQkFDS1RFU1RfVE9PTDsKCV9fc3RhcnRfXyAtLT4gSFlQT1RIRVNJUzsKCVJFVklFVyAtLi0+IEhZUE9USEVTSVM7CglSRVZJRVcgLS4gJm5ic3A7RU5EJm5ic3A7IC4tPiBfX2VuZF9fOwoJY2xhc3NEZWYgZGVmYXVsdCBmaWxsOiNmMmYwZmYsbGluZS1oZWlnaHQ6MS4yCgljbGFzc0RlZiBmaXJzdCBmaWxsLW9wYWNpdHk6MAoJY2xhc3NEZWYgbGFzdCBmaWxsOiNiZmI2ZmM=\");\n","    const mermaid = (await import(\"https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.esm.min.mjs\")).default;\n","\n","    mermaid.initialize({\n","      startOnLoad: false,\n","      securityLevel: \"strict\",\n","      theme: \"base\",\n","      fontFamily: \"ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, monospace\",\n","      themeVariables: {\"background\": \"#ffffff\", \"primaryColor\": \"#f2f5ff\", \"primaryBorderColor\": \"#111111\", \"primaryTextColor\": \"#000000\", \"secondaryColor\": \"#eef2ff\", \"secondaryBorderColor\": \"#111111\", \"secondaryTextColor\": \"#000000\", \"tertiaryColor\": \"#f7f7ff\", \"tertiaryBorderColor\": \"#111111\", \"tertiaryTextColor\": \"#000000\", \"lineColor\": \"#111111\", \"textColor\": \"#000000\", \"fontSize\": \"16px\"},\n","      flowchart: {\n","        curve: \"basis\",\n","        nodeSpacing: 44,\n","        rankSpacing: 60,\n","        padding: 12\n","      }\n","    });\n","\n","    const { svg } = await mermaid.render(\"mermaid_1737e440db\", code);\n","\n","    // Post-process: enforce black strokes + thicker lines + full opacity for print/projector\n","    const svg2 = svg\n","      .replaceAll('stroke-width=\"1\"', 'stroke-width=\"2.2\"')\n","      .replaceAll('opacity=\"0.7\"', 'opacity=\"1.0\"')\n","      .replaceAll('stroke: rgb(153, 153, 153)', 'stroke: #111111');\n","\n","    out.innerHTML = svg2;\n","  } catch (e) {\n","    err.textContent = \"Mermaid render error:\\n\" + (e?.stack || e?.message || String(e));\n","  }\n","</script>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Graph compiled. Mermaid length: 456\n"]}]},{"cell_type":"markdown","source":["##8.EXECUTION"],"metadata":{"id":"BLus531lirIL"}},{"cell_type":"markdown","source":["###8.1.OVERVIEW"],"metadata":{"id":"x0j2JYTnixuf"}},{"cell_type":"markdown","source":["**Cell 8 — Execute the workflow as a bounded, state-driven run (the “live” system)**\n","\n","Cell 8 is where the notebook stops being a specification and becomes an actual run. This cell takes the compiled graph and executes it against an initial state. In a classroom, this is the moment students see the system behave like a controlled research loop rather than a collection of functions.\n","\n","We define a `run_workflow()` function that creates an initial `N4State`. The initial state includes the run ID, an iteration counter, the maximum iteration budget, the user request, and empty containers for trace and errors. Notice what is not present: there is no implicit conversational memory and no hidden global state driving decisions. Everything that matters is inside `state`.\n","\n","We then run a bounded execution loop around the graph. This may look slightly redundant because LangGraph itself has conditional edges, but it serves an important governance purpose: it makes the iteration counter progression explicit and guarantees a hard bound even if a future modification accidentally weakens the router logic. Each cycle increments `iter_count` deterministically, then calls `graph.invoke(state)`. Inside that invocation, the graph runs `HYPOTHESIS → BACKTEST_TOOL → REVIEW`, and the conditional edge from REVIEW will either loop or stop.\n","\n","After the graph invocation returns, we check the decision in state. If the reviewer set `decision` to STOP, we break. If the iteration counter has reached the maximum, we break. This is a belt-and-suspenders approach: bounded loops are a professional necessity. In production, a runaway loop can burn API budget, flood logs, and create unpredictable behavior. Here, boundedness is also pedagogical: students should see that the system does not “keep thinking forever.” It behaves like a controlled process with a budget.\n","\n","At the end of the run, we print a compact summary: the final decision, iteration count, key backtest metrics, and the termination reason. This is intentionally short. The full detail is stored in state and will be exported in the next cells. This matches real workflows: a run produces an executive summary for quick inspection and a full artifact bundle for deeper review.\n","\n","The output you observed earlier—STOP after one iteration with negative Sharpe—was not an error in execution. It was the policy doing what it was told. After we updated Cell 6, negative Sharpe now triggers one refinement iteration (as long as budget remains). That change is precisely the point of Cell 8: the system’s behavior is controlled by explicit rules, so you can change behavior by changing policy, not by adding ad hoc manual steps.\n","\n","For financial practitioners, this cell demonstrates the operational pattern of governed research: you can run the same workflow repeatedly, compare results, and trust that the process is consistent. That is exactly what you need in a desk environment where multiple analysts must produce work that is reproducible and reviewable.\n"],"metadata":{"id":"CGJ3TUQwi2JO"}},{"cell_type":"markdown","source":["###8.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"SCv1wHOni2cy"}},{"cell_type":"code","source":["# CELL 8/10 — Execute bounded runs (state-driven). Iter counter updated deterministically between cycles.\n","def run_workflow(user_request: str) -> N4State:\n","    state: N4State = {\n","        \"run_id\": RUN_ID,\n","        \"iter_count\": 0,\n","        \"max_iters\": int(CFG[\"max_iters\"]),\n","        \"user_request\": user_request,\n","        \"trace\": [],\n","        \"hypothesis_errors\": [],\n","        \"decision\": \"ITERATE\",\n","    }\n","\n","    # Each cycle is a full graph pass; conditional edge decides whether we loop.\n","    # We increment iter_count deterministically before each pass.\n","    for _ in range(int(CFG[\"max_iters\"]) + 1):\n","        state[\"iter_count\"] = int(state.get(\"iter_count\", 0)) + 1\n","        state = graph.invoke(state, config={\"recursion_limit\": 30})\n","        if state.get(\"decision\") != \"ITERATE\":\n","            break\n","        if int(state.get(\"iter_count\", 0)) >= int(state.get(\"max_iters\", CFG[\"max_iters\"])):\n","            break\n","    return state\n","\n","USER_TASK = \"Propose a simple mean-reversion hypothesis and test it fast on synthetic data; reduce turnover while keeping Sharpe acceptable.\"\n","FINAL_STATE = run_workflow(USER_TASK)\n","\n","print(\"DECISION:\", FINAL_STATE.get(\"decision\"))\n","print(\"ITER_COUNT:\", FINAL_STATE.get(\"iter_count\"), \"/\", FINAL_STATE.get(\"max_iters\"))\n","print(\"BACKTEST_METRICS:\", stable_json_dumps((FINAL_STATE.get(\"backtest_json\", {}) or {}).get(\"metrics\", {})))\n","print(\"TERMINATION_REASON:\", FINAL_STATE.get(\"termination_reason\", \"n/a\"))\n"],"metadata":{"id":"s8BmlsxYiw1_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771441957600,"user_tz":360,"elapsed":7425,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"c503b954-93f5-46c4-cee3-66aade16fcf2"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["DECISION: STOP\n","ITER_COUNT: 1 / 2\n","BACKTEST_METRICS: {\"avg_turnover\":0.04054054054054054,\"max_drawdown\":-0.028357685393366694,\"sharpe_approx\":-0.35617625353483345,\"total_return\":-0.00908812327420816}\n","TERMINATION_REASON: STOP - Policy criteria not triggered. Strategy underperforms with negative Sharpe and negative returns. Low turnover and controlled drawdown insufficient to justify continuation. Recommend strategy re\n"]}]},{"cell_type":"markdown","source":["##9.EXPORT ARTIFACTS"],"metadata":{"id":"7JxS9vVQi4yB"}},{"cell_type":"markdown","source":["###9.1.0VERVIEW"],"metadata":{"id":"Wurgn_8fi5-m"}},{"cell_type":"markdown","source":["**Cell 9 — Export the audit artifacts (run_manifest.json, graph_spec.json, final_state.json)**\n","\n","Cell 9 is where the notebook becomes “institutional.” In real finance teams, what matters is not just that you got an answer, but that you can prove what you did. This cell exports three artifacts that capture the run in a way another person can inspect without rerunning the notebook.\n","\n","First, we define `write_json()`, a small utility that writes JSON with stable formatting: UTF-8 encoding, pretty indentation, and sorted keys. This matters for review. Sorted keys reduce noisy diffs when artifacts are compared in version control. Pretty formatting makes it readable for humans. Governance is not only about security; it is also about making review easy.\n","\n","Next, we update the run manifest with completion information. We add a completion timestamp and an `outputs_summary` block that includes the final decision, iteration count, termination reason, and key backtest metrics. This is important because it gives a reviewer a “front page.” They can open `run_manifest.json` and immediately see what happened, without opening the full final state. In professional settings, this is how you structure evidence: one document summarizes, other documents support.\n","\n","Then we write the three required files:\n","\n","**run_manifest.json** is the metadata record: who/what/when, configuration hash, environment fingerprint, and summary outcomes. It ties everything together under `run_id`.\n","\n","**graph_spec.json** is the structural record: nodes, edges, and loop bounds, plus the Mermaid text. It documents the process itself. This is important because results are meaningless without knowing the process that generated them. If someone changes topology later, you can detect that change by comparing graph specs.\n","\n","**final_state.json** is the full execution record: the structured hypothesis, the deterministic tool outputs, the review object, the decision, and the bounded trace. This is the deepest level of auditability. If someone asks, “What parameters did you test?” you can point to `final_state.json[\"hypothesis_json\"][\"hypothesis\"][\"params\"]`. If someone asks, “What exactly was the tool output?” you can point to `final_state.json[\"backtest_json\"]`. If someone asks, “Why did we stop?” you can point to `final_state.json[\"review_json\"]` and `termination_reason`.\n","\n","Finally, we print a list of written JSON files. This is a small sanity signal that the artifacts exist. In a classroom, students learn to expect artifacts as part of execution, not as an optional step.\n","\n","For financial practitioners, this cell is the difference between “a backtest” and “a reviewable research artifact.” In committees, risk reviews, and model governance, outputs without provenance are not accepted. Cell 9 enforces that provenance is produced every run, automatically, with no manual steps. That is how disciplined teams avoid the slow decay into unreproducible research.\n"],"metadata":{"id":"SYflANI7irC5"}},{"cell_type":"markdown","source":["###9.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"WvgKf0NEi8Tj"}},{"cell_type":"code","source":["# CELL 9/10 — Export required artifacts: run_manifest.json, graph_spec.json, final_state.json\n","def write_json(path: str, obj: Any) -> None:\n","    with open(path, \"w\", encoding=\"utf-8\") as f:\n","        f.write(json.dumps(obj, ensure_ascii=False, indent=2, sort_keys=True))\n","\n","RUN_MANIFEST[\"completed_ts_utc\"] = utc_now_iso()\n","RUN_MANIFEST[\"outputs_summary\"] = {\n","    \"decision\": FINAL_STATE.get(\"decision\"),\n","    \"iter_count\": FINAL_STATE.get(\"iter_count\"),\n","    \"termination_reason\": FINAL_STATE.get(\"termination_reason\", \"\"),\n","    \"key_metrics\": (FINAL_STATE.get(\"backtest_json\", {}) or {}).get(\"metrics\", {}),\n","}\n","\n","write_json(\"run_manifest.json\", RUN_MANIFEST)\n","write_json(\"graph_spec.json\", GRAPH_SPEC)\n","write_json(\"final_state.json\", FINAL_STATE)\n","\n","print(\"WROTE: run_manifest.json, graph_spec.json, final_state.json\")\n","print(\"FILES:\", [p for p in os.listdir(\".\") if p.endswith(\".json\")])\n"],"metadata":{"id":"Cjgofr2XWIz9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771442027382,"user_tz":360,"elapsed":15,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"a3c941d7-aa9b-461d-dc68-0655132a5177"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["WROTE: run_manifest.json, graph_spec.json, final_state.json\n","FILES: ['run_manifest.json', 'final_state.json', 'graph_spec.json']\n"]}]},{"cell_type":"markdown","source":["##10.AUDIT BUNDLE"],"metadata":{"id":"ss5L2x1ojA8d"}},{"cell_type":"markdown","source":["###10.1.OVERVIEW"],"metadata":{"id":"sduxTxx7jC0M"}},{"cell_type":"markdown","source":["**Cell 10 — Sanity checks and a readable audit view (trust but verify)**\n","\n","Cell 10 is the final control layer. In professional workflows, exporting artifacts is necessary but not sufficient. You also need quick validation that the artifacts are internally consistent and that the run produced what you think it produced. This cell provides that validation in a simple, teachable way.\n","\n","We start by defining `load_json()`, a minimal reader utility. Then we load the three exported artifacts: `run_manifest.json`, `graph_spec.json`, and `final_state.json`. Loading them back from disk is intentional. It verifies that what we wrote is valid JSON and that the files can be consumed by downstream processes. In real systems, this is how you test that your pipeline is not writing corrupted or partial outputs.\n","\n","Next, we run a few assertions. We check that the `run_id` is consistent across all three files. This matters because the run ID is the join key that connects metadata, topology, and execution results. If run IDs diverge, you can accidentally pair the wrong graph spec with the wrong final state, which is a serious audit failure. We also assert that the Mermaid text exists in the graph spec. This ensures the visualization artifact is present and prevents “silent skipping” of the diagram requirement.\n","\n","Then we print a compact “audit view.” The goal is to give a human reviewer the key facts in a few lines: run ID, start and completion timestamps, model lock, configuration hash, the list of graph nodes, the final decision, and the final metrics. This printout is not meant to replace the JSON artifacts. It is meant to be the quick dashboard you look at immediately after a run to confirm nothing obviously broke.\n","\n","Finally, we print the tail of the trace. The trace is a bounded list of node events with timestamps and small payloads. By printing only the last few entries, we keep the output readable and avoid flooding the notebook. This is important pedagogically: students should learn that logs exist, but logs must be bounded and curated to remain useful. The tail trace lets you see the last transitions—typically HYPOTHESIS, BACKTEST_TOOL, REVIEW—and confirm that the workflow actually passed through the intended path.\n","\n","For financial practitioners, this cell maps to a basic model control practice: validate artifacts and check invariants. You do not ship results that have not passed internal consistency checks. Even in research, you want immediate detection of mismatches: wrong model, wrong config, missing graph, or missing outputs. Cell 10 provides that minimum assurance.\n","\n","In summary, Cell 10 closes the loop: the system is not only state-driven and tool-augmented, it is also self-checking. That is the mindset we want for real trading and research environments: deterministic where possible, explicit everywhere, and always producing evidence that can be reviewed.\n"],"metadata":{"id":"bqPR0OmsWKLt"}},{"cell_type":"markdown","source":["###10.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"v_giRgoJjGY5"}},{"cell_type":"code","source":["# CELL 10/10 — Audit sanity checks + readable tail trace (bounded)\n","def load_json(path: str) -> Any:\n","    with open(path, \"r\", encoding=\"utf-8\") as f:\n","        return json.load(f)\n","\n","rm = load_json(\"run_manifest.json\")\n","gs = load_json(\"graph_spec.json\")\n","fs = load_json(\"final_state.json\")\n","\n","assert rm[\"run_id\"] == RUN_ID\n","assert gs[\"run_id\"] == RUN_ID\n","assert fs[\"run_id\"] == RUN_ID\n","assert \"mermaid\" in gs and isinstance(gs[\"mermaid\"], str) and len(gs[\"mermaid\"]) > 0\n","\n","print(\"=== AUDIT VIEW ===\")\n","print(\"RUN:\", rm[\"run_id\"])\n","print(\"TS_UTC:\", rm[\"ts_utc\"], \"→\", rm.get(\"completed_ts_utc\"))\n","print(\"MODEL_LOCK:\", rm[\"model_lock\"])\n","print(\"CONFIG_HASH_SHA256:\", rm[\"config_hash_sha256\"])\n","print(\"GRAPH_NODES:\", [n[\"id\"] for n in gs[\"nodes\"]])\n","print(\"FINAL_DECISION:\", fs.get(\"decision\"))\n","print(\"FINAL_METRICS:\", stable_json_dumps((fs.get(\"backtest_json\", {}) or {}).get(\"metrics\", {})))\n","\n","tail = (fs.get(\"trace\", []) or [])[-6:]\n","print(\"TRACE_TAIL_JSON:\")\n","print(json.dumps(tail, ensure_ascii=False, indent=2))\n"],"metadata":{"id":"Lrqr5DdYjK83","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771442058414,"user_tz":360,"elapsed":47,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"e62ce1d4-a37f-410d-a19b-746856855c4b"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["=== AUDIT VIEW ===\n","RUN: 55d054f6-1440-4610-b200-179c581a0c52\n","TS_UTC: 2026-02-18T19:08:17.589257+00:00 → 2026-02-18T19:13:48.199569+00:00\n","MODEL_LOCK: {'model': 'claude-haiku-4-5-20251001', 'temperature': 0.0}\n","CONFIG_HASH_SHA256: 9d8ef239f6baf1aca86fc5129ece19fee6bbd9e0e4612211913b2fa7081fa376\n","GRAPH_NODES: ['HYPOTHESIS', 'BACKTEST_TOOL', 'REVIEW', 'END']\n","FINAL_DECISION: STOP\n","FINAL_METRICS: {\"avg_turnover\":0.04054054054054054,\"max_drawdown\":-0.028357685393366694,\"sharpe_approx\":-0.35617625353483345,\"total_return\":-0.00908812327420816}\n","TRACE_TAIL_JSON:\n","[\n","  {\n","    \"node\": \"HYPOTHESIS\",\n","    \"payload\": {\n","      \"errors\": [],\n","      \"iter\": 1,\n","      \"params\": {\n","        \"lookback\": 20,\n","        \"max_leverage\": 0.75,\n","        \"threshold_z\": 2.0\n","      }\n","    },\n","    \"ts_utc\": \"2026-02-18T19:12:35.555129+00:00\"\n","  },\n","  {\n","    \"node\": \"BACKTEST_TOOL\",\n","    \"payload\": {\n","      \"metrics\": {\n","        \"avg_turnover\": 0.04054054054054054,\n","        \"max_drawdown\": -0.028357685393366694,\n","        \"sharpe_approx\": -0.35617625353483345,\n","        \"total_return\": -0.00908812327420816\n","      },\n","      \"params\": {\n","        \"fee_bps_daily\": 0.0,\n","        \"impact_bps_per_turnover\": 8.0,\n","        \"lookback\": 20,\n","        \"max_leverage\": 0.75,\n","        \"threshold_z\": 2.0\n","      }\n","    },\n","    \"ts_utc\": \"2026-02-18T19:12:35.557134+00:00\"\n","  },\n","  {\n","    \"node\": \"REVIEW\",\n","    \"payload\": {\n","      \"decision\": \"STOP\",\n","      \"key_metrics\": {\n","        \"avg_turnover\": 0.04054054054054054,\n","        \"max_drawdown\": -0.028357685393366694,\n","        \"sharpe_approx\": -0.35617625353483345,\n","        \"total_return\": -0.00908812327420816\n","      }\n","    },\n","    \"ts_utc\": \"2026-02-18T19:12:38.347743+00:00\"\n","  }\n","]\n"]}]},{"cell_type":"markdown","source":["##11.CONCLUSION"],"metadata":{"id":"ZmL0B12KjLXl"}},{"cell_type":"markdown","source":["Imagine you are in a morning research meeting on a trading desk.\n","\n","A junior analyst says: “I have an idea. When yesterday’s move is unusually big, the price might mean-revert tomorrow.”  \n","The PM replies: “Fine. Test it quickly. But don’t waste the whole day. And I want something I can review.”\n","\n","This notebook is the **machine that produces that reviewable answer**.\n","\n","It does **not** place real trades.\n","It does **not** send orders.\n","It runs a **controlled simulation** to decide whether the idea is worth any further work.\n","\n","Here is what happens, like a story:\n","\n","**Step 1: The system writes down the idea in a strict format**\n","The workflow starts at a node called **HYPOTHESIS**.\n","Think of it as the analyst being forced to write the idea clearly:\n","\n","- What is the strategy family? (fixed here: mean-reversion z-score)\n","- What parameters are you proposing? (lookback, threshold, leverage)\n","- What are the risks?\n","- What should we check to see if it fails?\n","\n","So the first deliverable is: **a structured hypothesis**, not a chart, not a narrative.\n","\n","**Step 2: The system tests the idea using a calculator, not imagination**\n","Next the workflow goes to **BACKTEST_TOOL**.\n","This is a deterministic tool (pure code), like a “research calculator.”\n","\n","It generates a **synthetic price series** (fake but consistent, like a flight simulator).  \n","Then it applies the hypothesis rules to create **simulated positions** (long/short/flat).  \n","Those positions create **simulated P&L**.\n","\n","From this, the tool computes concrete numbers:\n","\n","- total return\n","- approximate Sharpe\n","- max drawdown\n","- average turnover\n","\n","So the second deliverable is: **a structured backtest result** produced by code.\n","\n","**Step 3: The system decides whether to spend one more minute or stop**\n","Then we reach **REVIEW**.\n","This is like a senior researcher applying a desk rule:\n","\n","- “If it’s clearly bad, stop.”\n","- “If it’s weak but might improve with one small, justified change, allow one more test.”\n","- “Never iterate forever. We have a time budget.”\n","\n","So the system outputs one decision:\n","\n","- **ITERATE** (go back and test once more with a parameter adjustment), or\n","- **STOP** (end the workflow and park/reject the idea at this gate)\n","\n","This is the third deliverable: **a documented decision and the reason for it**.\n","\n","**What does an iteration mean?**\n","One iteration means:\n","“We changed one small thing (like a threshold or leverage) and re-ran the same test.”\n","\n","It does not mean “keep searching until we like the result.”\n","It means “one controlled refinement pass, then we stop.”\n","\n","**What happens when we STOP?**\n","STOP means:\n","“We are done with this quick triage workflow.”\n","\n","In real life, STOP can mean two practical outcomes:\n","\n","1) **Reject/Park**  \n","The idea did not look good enough to justify more research time right now.\n","\n","2) **Escalate to a deeper process (outside this notebook)**  \n","If results were promising, STOP can also mean:  \n","“Stop the quick test here and move to a more serious evaluation stage”\n","(real data, better costs, stress tests, governance review).\n","\n","But this notebook’s job ends at the gate.\n","It produces evidence so a human can choose the next step.\n","\n","**So what is the final deliverable, in plain language?**\n","At the end you receive a small “research folder”:\n","\n","- A diagram showing the workflow steps (the graph)\n","- A file that records the run identity and environment (**run_manifest.json**)\n","- A file that records the workflow structure (**graph_spec.json**)\n","- A file that contains the hypothesis, the test results, and the stop/iterate decision (**final_state.json**)\n","\n","That folder is the deliverable.\n","\n","It answers, concretely:\n","“What was the idea, what test did we run, what did we measure, and why did we stop (or refine once)?”\n","\n"],"metadata":{"id":"tv8ReGkpWL8u"}},{"cell_type":"code","source":[],"metadata":{"id":"O0G6E7TXRJNk"},"execution_count":null,"outputs":[]}]}