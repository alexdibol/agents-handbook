{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","toc_visible":true,"authorship_tag":"ABX9TyNMdi5xFEYlAqVxFtaA2egb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#**CHAPTER 6.REBALANCE COMMITTEE**\n","---"],"metadata":{"id":"rgzq7ad4oQsb"}},{"cell_type":"markdown","source":["##REFERENCE"],"metadata":{"id":"nBRtjho5h2Cg"}},{"cell_type":"markdown","source":["https://chatgpt.com/share/699652ec-6544-8012-818a-c1d3d415c384"],"metadata":{"id":"SCQp1W1bWDl0"}},{"cell_type":"markdown","source":["##0.CONTEXT"],"metadata":{"id":"qWHgDkx8h5mE"}},{"cell_type":"markdown","source":["**CHAPTER 6 / NOTEBOOK 6 — Portfolio Rebalance as a Committee, Not a Monologue**\n","\n","A portfolio rebalance sounds deceptively simple when you say it fast: “take the current weights, apply a view, respect constraints, produce trades.” In practice, it is one of those tasks where the math is clean and the organization is messy. The decision is never only about expected return. It is simultaneously about risk posture, transaction costs, feasibility, governance, and accountability. The real difficulty is not computing a vector of trades. The real difficulty is making a decision that a team can defend, reproduce, and audit after the fact, when the market moves and someone asks, “Why did you do that?”\n","\n","This notebook’s architecture solves that institutional problem: **how to turn a rebalance into a controlled, parallel, reviewable process** rather than a single “smart” output. The goal is not to maximize cleverness. The goal is to encode a disciplined workflow: multiple perspectives are expressed in parallel, their outputs are aggregated deterministically, disagreements are measured explicitly, and the system terminates with a clear gate: approve, reject, or escalate to human review. In other words, the architecture is not trying to be a genius trader. It is trying to be a **reliable committee secretary** with perfect memory for what happened, who did what, and why the process stopped.\n","\n","To understand the point, imagine a real investment team on a rebalance day. The portfolio manager has a calendar invite titled “Monthly Rebalance — 45 minutes.” That title is a lie. The meeting is never 45 minutes, because the portfolio is not just a spreadsheet. It is a living set of exposures, client constraints, internal policies, and market frictions. The team walks in with three different anxieties: the risk person worries about concentration and volatility, the execution person worries about turnover and slippage, and the research person worries about missing the signal and drifting from the strategy’s intention. They can all be correct at the same time. The team’s real task is not to “pick the right answer” but to negotiate a decision that is coherent under constraint.\n","\n","In a human workflow, the committee usually begins with an intake. Someone states the portfolio universe and current weights; someone confirms constraints: maximum position size, turnover limits, and any “do not touch” rules. Someone provides a market snapshot: a rough estimate of which names are volatile, which are expensive to trade, which have positive or negative signal. Then the meeting splits into perspective-specific conversations. The risk person says: “We’re too heavy in high-vol names; reduce tail exposure.” The execution person says: “You can do that, but you’ll pay; avoid high-impact trades; minimize churn.” The research person says: “But the model is flashing; if we don’t rotate, we’re ignoring our own signal.” A human PM then synthesizes this tension into a plan. Sometimes the plan is easy: all three agree. Sometimes it is not: the arguments conflict, the trades are large, and the decision is pushed to a senior committee.\n","\n","This notebook implements that exact workflow as a state-driven agent system. The architecture is not a chat. It is a directed process with explicit nodes, a typed state, and deterministic routing. The state is the shared “whiteboard” that the whole team writes on: it includes the portfolio, the constraints, the synthetic market snapshot, the committee’s intermediate reports, and the final decision. The system does not rely on “implicit memory” or hidden context. Every decision is produced by functions that update state in traceable increments. If a node fails, it writes an error into state. If a node succeeds, it writes a trace event into state. This is a governance-first approach: state is not merely data; it is the audit record.\n","\n","The key architectural move in this notebook is **parallel committee deliberation**. Instead of asking one model to produce “the” rebalance, the system runs three LLM tasks in parallel, each constrained to a single mandate. In human terms: we are assigning three analysts to produce three memos at the same time. The risk analyst produces a “risk-first” trade suggestion, the cost analyst produces a “cost-first” suggestion, and the signal analyst produces a “signal-first” suggestion. Each is forced to output strict JSON, not prose. This matters because the committee outputs are not meant to persuade; they are meant to be merged and tested. A persuasive paragraph is not a trade list. A trade list is an object that can be constrained, scaled, and audited.\n","\n","Parallel work introduces a second institutional reality: concurrency creates collisions. Two people can speak at once; two memos can mention the same trade; two errors can occur in parallel. The architecture handles this with explicit merge channels in the state schema. Certain state fields are designed to accept multiple updates in the same step (for example, committee reports, trace events, and error messages). This is not an implementation detail; it is a modeling choice: it recognizes that a committee is not a single stream of thought. It is a multi-stream process that must be collected and reconciled without losing information.\n","\n","Once the committee outputs exist, the system transitions from “creative proposal” to “mechanical aggregation.” This is the heart of the control philosophy: **LLM creativity is bounded to the proposal phase; aggregation is deterministic**. The reducer node is the portfolio manager’s calculator. It takes the three trade suggestions and merges them using fixed weights across perspectives. It then enforces constraints. If trades violate maximum weights, it clips. If turnover is too high, it scales trades down to respect the cap. If the trade list is noisy, it prunes tiny changes. This mirrors how real desks operate: the meeting can be open-ended, but the final blotter must obey rules. The reducer makes sure the output is feasible and consistent with declared constraints, without requiring the LLM to “remember” those rules perfectly.\n","\n","Then comes the gate. Every institutional process needs a stop/go control point, because teams fail in two ways: they either push decisions through without scrutiny, or they talk forever and never act. The gate is designed to avoid both failure modes. It asks: did any node emit errors? If yes, the system stops and requests human review. If no, did the committee disagree strongly? If disagreement is above a threshold, the system can run a bounded rerun for stability (at most a fixed number of rounds). This is a controlled version of what humans do when they sense uncertainty: “Let’s sanity-check. Let’s re-run the analysis. Let’s see if the recommendation is stable.” The key is boundedness. We never allow infinite loops. The system can re-run once for stability, and then it must stop. That creates a discipline: escalation is not a failure; it is an expected outcome when information is insufficient or when the team cannot converge.\n","\n","This is the narrative the notebook is teaching: **a rebalance decision is a governance problem first and a numerical problem second**. Without explicit controls, an LLM-based workflow degenerates into a single persuasive output that nobody can reproduce. With controls, the system behaves like a small institution: intake, parallel deliberation, deterministic aggregation, explicit stage gate, and artifact export. The artifacts are not decorative. They are the deliverables that make the workflow reviewable: a run manifest (what code and config was used), a graph spec (what topology was executed), and a final state (what happened and what was decided). In a real organization, these are the documents that protect you when something goes wrong. They let you answer questions like: Which model produced the committee suggestions? What constraints were applied? How many rounds were attempted? Why did the system stop? What errors occurred? What trades were proposed?\n","\n","The notebook is also honest about what it is not doing. It is not executing trades. It is not claiming alpha. It is not optimizing a full risk model. It is teaching the structural pattern: **parallel committee + aggregation**. That pattern is reusable. You can swap the synthetic portfolio for a real one, swap the synthetic snapshot for a real factor/risk feed, and keep the topology. You can add more committee members (compliance, liquidity, tax) without rewriting the whole system. You can harden constraints and expand audit logs. The design scales because the structure is modular: each node has a single job, the state schema is explicit, and the routing rules are deterministic.\n","\n","If you picture the architecture as a human team, it looks like this. The intake node is the operations associate who assembles the pack. The committee members are three analysts who write focused memos in parallel. The reducer is the portfolio manager’s spreadsheet that turns memos into a feasible plan. The gate is the investment committee chair who decides whether the plan is approved or needs escalation. And the artifact exporter is the risk-control function that files the run: “This is what we did, this is why, and this is the evidence we can show.”\n","\n","That is the story this notebook tells: not the story of a model “deciding” a rebalance, but the story of a controlled process that turns multiple partial truths into one accountable output. In institutional finance, that difference is everything.\n"],"metadata":{"id":"pF_yDrZ7h6_y"}},{"cell_type":"markdown","source":["##1.LIBRARIES AND ENVIRONMENT"],"metadata":{"id":"yeIrVzqFh7fZ"}},{"cell_type":"markdown","source":["**CELL 1/10 — Libraries and environment (why we pin and verify)**\n","\n","This first cell is the “foundation slab” of the notebook. In Colab, you are not starting from a clean machine. You are starting from a crowded kitchen where multiple chefs already left ingredients on the counter. That’s why we do two things that look boring but are absolutely essential for a classroom-grade workflow: **pin versions** and **verify the environment**.\n","\n","Pinning means we force specific package versions (requests, numpy, pydantic, httpx, langgraph, langchain, etc.) so every student gets the same behavior. In finance, reproducibility is not a “nice to have.” If a rebalance process produces different outputs on different machines, you cannot defend it. A portfolio committee cannot rely on “it worked on my laptop.” This is why we print `CONFIG` and `VERSIONS`. You want to know exactly what model is locked, what thresholds are set, and what libraries were loaded.\n","\n","The notebook also handles a known Colab problem: preinstalled packages often conflict with your pins. The pip warning you saw earlier is exactly that. The fix is: **install with force-reinstall** and then run `pip check`. If `pip check` complains, you want to see it immediately. Silent dependency conflicts lead to confusing runtime errors later (for example, an API call failing because a library downgraded a dependency behind your back).\n","\n","The `VERSION_MISMATCH` dictionary is a simple but powerful control. It tells you: “Did the pins actually apply?” If it is empty, your environment matches the intended teaching setup. If it is not empty, you should restart runtime once, because Python can keep old modules in memory even after pip installs new ones. This is not theoretical; it’s the most common source of “why does it still behave like the old version?”\n","\n","Finally, we set deterministic seeds (`random.seed`, `PYTHONHASHSEED`). Even though we use an LLM later, we still want everything else to be deterministic: synthetic portfolio generation, synthetic features, and aggregation logic. The point is: you can vary the LLM, but you should not vary the plumbing.\n","\n","So Cell 1 is not just “install stuff.” It is your first governance control: **a reproducible, inspectable environment** that makes every run explainable.\n"],"metadata":{"id":"HhMLP197MWyg"}},{"cell_type":"code","source":["# CELL 1/10 — Install + core imports (Colab hardened + remove langgraph-prebuilt conflicts)\n","\n","# 1) Remove the conflicting prebuilt package if present (non-fatal if absent)\n","!pip -q uninstall -y langgraph-prebuilt || true\n","\n","# 2) Install pinned stack aligned with Colab constraints\n","!pip -q install --upgrade --force-reinstall \\\n","  \"requests==2.32.4\" \\\n","  \"numpy==2.0.2\" \\\n","  \"pydantic==2.12.3\" \\\n","  \"httpx==0.28.1\" \"httpcore==1.0.5\" \\\n","  \"langgraph==0.2.39\" \"langchain==0.3.14\" \"langchain-core==0.3.40\" \\\n","  \"anthropic>=0.34.0\"\n","\n","# sanity: dependency integrity (review if it complains)\n","!pip -q check || true\n","\n","import os, json, uuid, time, random, hashlib, platform, re\n","import datetime as _dt\n","from typing import TypedDict, Literal, Dict, Any, List, Optional, Callable, Tuple\n","from typing_extensions import Annotated\n","import operator\n","\n","import httpx\n","from google.colab import userdata\n","from IPython.display import HTML, display\n","from langgraph.graph import StateGraph, END\n","\n","random.seed(7)\n","os.environ[\"PYTHONHASHSEED\"] = \"7\"\n","\n","import importlib.metadata as md\n","def _ver(pkg: str) -> str:\n","    try:\n","        return md.version(pkg)\n","    except Exception:\n","        return \"missing\"\n","\n","CONFIG: Dict[str, Any] = {\n","    \"project\": \"AA-FIN-LG-2026\",\n","    \"notebook\": \"N6 — Portfolio Rebalance: Parallel Committee + Aggregation\",\n","    \"model\": \"claude-haiku-4-5-20251001\",\n","    \"temperature\": 0.0,\n","    \"max_tokens\": 700,\n","    \"seed\": 7,\n","    \"max_rounds\": 2,\n","    \"disagreement_threshold\": 0.18,\n","    \"committee_perspectives\": [\"risk\", \"cost\", \"signal\"],\n","}\n","\n","VERSIONS = {\n","    \"python\": platform.python_version(),\n","    \"platform\": platform.platform(),\n","    \"requests\": _ver(\"requests\"),\n","    \"numpy\": _ver(\"numpy\"),\n","    \"pydantic\": _ver(\"pydantic\"),\n","    \"httpx\": _ver(\"httpx\"),\n","    \"httpcore\": _ver(\"httpcore\"),\n","    \"langgraph\": _ver(\"langgraph\"),\n","    \"langchain\": _ver(\"langchain\"),\n","    \"langchain-core\": _ver(\"langchain-core\"),\n","    \"anthropic\": _ver(\"anthropic\"),\n","    \"langgraph-prebuilt\": _ver(\"langgraph-prebuilt\"),  # should become \"missing\"\n","}\n","\n","print(\"CONFIG:\", json.dumps(CONFIG, indent=2))\n","print(\"VERSIONS:\", json.dumps(VERSIONS, indent=2))\n","print(\"UTC_NOW:\", _dt.datetime.now(_dt.timezone.utc).isoformat())\n","\n","EXPECTED = {\n","    \"requests\": \"2.32.4\",\n","    \"numpy\": \"2.0.2\",\n","    \"pydantic\": \"2.12.3\",\n","    \"httpx\": \"0.28.1\",\n","    \"httpcore\": \"1.0.5\",\n","    \"langgraph\": \"0.2.39\",\n","    \"langchain\": \"0.3.14\",\n","    \"langchain-core\": \"0.3.40\",\n","}\n","mismatch = {k: {\"expected\": EXPECTED[k], \"got\": VERSIONS.get(k)} for k in EXPECTED if VERSIONS.get(k) != EXPECTED[k]}\n","print(\"VERSION_MISMATCH:\", json.dumps(mismatch, indent=2))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"weuUs5AjApiP","executionInfo":{"status":"ok","timestamp":1771456126466,"user_tz":360,"elapsed":30886,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"edc11d4b-d11d-40c9-8db0-aa91429972f2"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["CONFIG: {\n","  \"project\": \"AA-FIN-LG-2026\",\n","  \"notebook\": \"N6 \\u2014 Portfolio Rebalance: Parallel Committee + Aggregation\",\n","  \"model\": \"claude-haiku-4-5-20251001\",\n","  \"temperature\": 0.0,\n","  \"max_tokens\": 700,\n","  \"seed\": 7,\n","  \"max_rounds\": 2,\n","  \"disagreement_threshold\": 0.18,\n","  \"committee_perspectives\": [\n","    \"risk\",\n","    \"cost\",\n","    \"signal\"\n","  ]\n","}\n","VERSIONS: {\n","  \"python\": \"3.12.12\",\n","  \"platform\": \"Linux-6.6.105+-x86_64-with-glibc2.35\",\n","  \"requests\": \"2.32.4\",\n","  \"numpy\": \"2.0.2\",\n","  \"pydantic\": \"2.12.3\",\n","  \"httpx\": \"0.28.1\",\n","  \"httpcore\": \"1.0.5\",\n","  \"langgraph\": \"0.2.39\",\n","  \"langchain\": \"0.3.14\",\n","  \"langchain-core\": \"0.3.40\",\n","  \"anthropic\": \"0.82.0\",\n","  \"langgraph-prebuilt\": \"missing\"\n","}\n","UTC_NOW: 2026-02-18T23:08:46.405196+00:00\n","VERSION_MISMATCH: {}\n"]}]},{"cell_type":"markdown","source":["##2.VISUALIZATION STANDARDS"],"metadata":{"id":"aOzs2vNWiEjE"}},{"cell_type":"markdown","source":["###2.1.OVERVIEW"],"metadata":{"id":"_Z7ptw6JiIcM"}},{"cell_type":"markdown","source":["**CELL 2/10 — Visualization standard (why the graph is mandatory)**\n","\n","Cell 2 is the “map on the wall.” In agentic systems, especially in finance, you cannot teach or review a workflow if the topology is invisible. People will misunderstand what runs first, what runs in parallel, and where loops occur. That misunderstanding becomes operational risk. So we make visualization a first-class requirement: **every notebook must render the LangGraph topology**.\n","\n","The key is the hardened Mermaid ESM renderer. We pin Mermaid to a specific version (`10.6.1`) and load it through a module import inside Colab. This avoids external rendering services and avoids version drift. If you rely on some third-party endpoint, you introduce a hidden dependency that can fail during a lecture. If you rely on “whatever Mermaid version Colab happens to have,” you risk diagrams that render differently or break after an update. Pinned versions are governance.\n","\n","The helper `display_langgraph_mermaid(compiled_graph)` does two jobs: it extracts the mermaid string from the compiled graph and then renders it in the notebook. We also return the mermaid string so we can export it later as part of the audit artifacts. That mermaid is not decorative. It is evidence of the workflow that ran.\n","\n","This notebook’s topology matters because it introduces the new architectural dimension: **parallel committee deliberation**. The diagram must show: entry into intake, fan-out into multiple committee_member branches, merge back into committee_reduce, then gate, then either loop (bounded) or END. If a student sees a serial chain, they will think it is “one model doing everything.” If they see the map-reduce structure, they understand the institutional metaphor: multiple analysts in parallel, then a portfolio manager aggregating.\n","\n","The “strict security level” in Mermaid is also not random. It prevents unsafe HTML or scripts from being injected into the visualization. In governed workflows, you treat rendering as an output surface that should be hardened, not as a toy.\n","\n","So Cell 2 is a teaching control: it forces everyone to see the same structure, and it makes the architecture reviewable at a glance. In finance terms, it is like insisting that every process has an up-to-date process flow diagram attached to the policy.\n"],"metadata":{"id":"jAsIm-aiiLkE"}},{"cell_type":"markdown","source":["###2.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"AK_Iz2Q4iL4X"}},{"cell_type":"code","source":["# CELL 2/10 — Visualization Standard v1: Hardened Mermaid ESM renderer + graph display helper\n","\n","MERMAID_VERSION = \"10.6.1\"  # pinned unless discussed\n","\n","def _escape_html(s: str) -> str:\n","    return (s.replace(\"&\", \"&amp;\")\n","             .replace(\"<\", \"&lt;\")\n","             .replace(\">\", \"&gt;\"))\n","\n","def render_mermaid_locally(mermaid_code: str, *, height_px: int = 560) -> None:\n","    \"\"\"\n","    Hardened Mermaid renderer for Colab using Mermaid ESM from a pinned version.\n","    - Avoids external services\n","    - Uses module import from unpkg\n","    - Sanitizes and renders deterministically\n","    \"\"\"\n","    safe = _escape_html(mermaid_code)\n","    diagram_id = f\"mmd-{abs(hash(mermaid_code)) % 10_000_000}\"\n","\n","    html = f\"\"\"\n","<div style=\"border:1px solid rgba(0,0,0,0.12); border-radius:12px; padding:12px; overflow:auto; height:{height_px}px;\">\n","  <div id=\"{diagram_id}\" class=\"mermaid\">\n","{safe}\n","  </div>\n","</div>\n","\n","<script type=\"module\">\n","  import mermaid from \"https://unpkg.com/mermaid@{MERMAID_VERSION}/dist/mermaid.esm.min.mjs\";\n","  mermaid.initialize({{\n","    startOnLoad: false,\n","    securityLevel: \"strict\",\n","    theme: \"default\",\n","    flowchart: {{ curve: \"linear\" }},\n","    maxTextSize: 200000\n","  }});\n","  const el = document.getElementById(\"{diagram_id}\");\n","  const code = el.textContent;\n","  const {{ svg }} = await mermaid.render(\"{diagram_id}-svg\", code);\n","  el.innerHTML = svg;\n","</script>\n","\"\"\"\n","    display(HTML(html))\n","\n","def display_langgraph_mermaid(compiled_graph: Any) -> str:\n","    \"\"\"\n","    Mandatory visualization helper.\n","    Returns the mermaid string and renders it in-notebook.\n","    \"\"\"\n","    # LangGraph compiled graphs typically expose get_graph().draw_mermaid()\n","    mmd = compiled_graph.get_graph().draw_mermaid()\n","    render_mermaid_locally(mmd)\n","    return mmd\n","\n","print(\"Mermaid pinned version:\", MERMAID_VERSION)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HV8T61sxA7Ts","executionInfo":{"status":"ok","timestamp":1771456151854,"user_tz":360,"elapsed":7,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"dc7db889-2167-48dc-9c9e-f940276a0221"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mermaid pinned version: 10.6.1\n"]}]},{"cell_type":"markdown","source":["##3.STATE SCHEMA"],"metadata":{"id":"zn9_gpBPh_yn"}},{"cell_type":"markdown","source":["###3.1.OVERVIEW"],"metadata":{"id":"6Sg0lGxQiBj6"}},{"cell_type":"markdown","source":["**CELL 3/10 — Typed state + merge channels + AgentNode abstraction (the control core)**\n","\n","Cell 3 is the “constitution” of the whole system. It defines what the workflow is allowed to know and what it is allowed to change. We implement that with an explicit `TypedDict` called `RebalanceState`. This is not just Python typing for aesthetics. It is a governance mechanism: it forces the notebook to treat state as a structured object, not as a bag of hidden variables.\n","\n","The biggest lesson in this notebook is that parallel workflows require explicit merge logic. In a parallel committee, multiple branches may update the same conceptual field in the same step. For example, three committee members produce three reports at once. If you store those in a normal list field, LangGraph will throw an error because it does not know how to merge concurrent updates. That is why we use `Annotated[List[...], operator.add]` for `committee_reports`, and we do the same for `errors` and `trace`.\n","\n","This is the “institutional” part: multiple people can file notes simultaneously, and you need a deterministic rule to combine them. Here the rule is simple: **concatenate lists**. That means each node returns only a delta (for example, one report), and LangGraph merges them into the full list.\n","\n","The `AgentNode` abstraction is required by your project rules and is also the right mental model. Each node is a wrapper around a pure function that maps `state -> patch`. The wrapper adds two controls automatically: (1) a trace event on success, and (2) an error capture on failure. Importantly, the wrapper emits only deltas for mergeable keys. That prevents concurrency collisions and keeps updates auditable.\n","\n","This design is the opposite of a “chatbot.” A chatbot hides its process inside text. Here the process is explicit: node name, timing, success/failure, and updates are visible in state. When something goes wrong, you don’t guess; you read the error list and the trace log.\n","\n","Cell 3 therefore establishes the core discipline of the project: **state drives routing, routing drives execution, execution produces artifacts**. Everything else in the notebook is built on this foundation.\n"],"metadata":{"id":"B7g7qJgZiEOw"}},{"cell_type":"markdown","source":["###3.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"SqN4lQyuiE7Y"}},{"cell_type":"code","source":["# CELL 3/10 — State schema (TypedDict) + audit helpers + AgentNode abstraction (parallel-safe)\n","\n","import operator\n","from typing_extensions import Annotated\n","\n","def utc_now() -> str:\n","    return _dt.datetime.now(_dt.timezone.utc).isoformat()\n","\n","def stable_hash(obj: Any) -> str:\n","    b = json.dumps(obj, sort_keys=True, ensure_ascii=False).encode(\"utf-8\")\n","    return hashlib.sha256(b).hexdigest()\n","\n","def write_json(path: str, obj: Any) -> None:\n","    with open(path, \"w\", encoding=\"utf-8\") as f:\n","        json.dump(obj, f, indent=2, ensure_ascii=False)\n","\n","class RebalanceState(TypedDict, total=False):\n","    # governance + metadata\n","    run_id: str\n","    ts_utc: str\n","    config: Dict[str, Any]\n","    versions: Dict[str, Any]\n","\n","    # portfolio + inputs\n","    universe: List[str]\n","    holdings: Dict[str, float]          # current weights\n","    target_policy: Dict[str, Any]       # policy definition\n","    constraints: Dict[str, Any]         # max weight, turnover cap, etc.\n","    market_snapshot: Dict[str, Any]     # synthetic risk/cost/signal features\n","\n","    # committee process\n","    round: int\n","    committee_perspectives: List[str]\n","    committee_expected: int\n","    committee_reports: Annotated[List[Dict[str, Any]], operator.add]  # MAP merge channel\n","    committee_scores: Dict[str, Any]\n","\n","    # outputs\n","    proposed_trades: Dict[str, float]   # delta weights\n","    rebalance_decision: Dict[str, Any]  # final decision + rationale\n","    final_decision: Literal[\"APPROVE\", \"HUMAN_REVIEW\", \"REJECT\"]\n","\n","    # control + audit (parallel-safe merge channels)\n","    errors: Annotated[List[str], operator.add]\n","    trace: Annotated[List[Dict[str, Any]], operator.add]\n","\n","class AgentNode:\n","    \"\"\"\n","    Required abstraction.\n","    IMPORTANT: For keys that can be updated in parallel steps (errors/trace/committee_reports),\n","    the node must emit ONLY deltas, letting LangGraph merge them via Annotated operators.\n","    \"\"\"\n","    def __init__(self, name: str, fn: Callable[[RebalanceState], Dict[str, Any]]):\n","        self.name = name\n","        self.fn = fn\n","\n","    def __call__(self, state: RebalanceState) -> Dict[str, Any]:\n","        t0 = time.time()\n","        try:\n","            patch = self.fn(state)\n","            dt_ms = int((time.time() - t0) * 1000)\n","            evt = {\"ts_utc\": utc_now(), \"node\": self.name, \"ms\": dt_ms, \"ok\": True}\n","            return {**patch, \"trace\": [evt]}  # delta only (merged)\n","        except Exception as e:\n","            dt_ms = int((time.time() - t0) * 1000)\n","            msg = f\"{self.name} error: {type(e).__name__}: {str(e)}\"\n","            evt = {\"ts_utc\": utc_now(), \"node\": self.name, \"ms\": dt_ms, \"ok\": False, \"error\": msg}\n","            return {\"errors\": [msg], \"trace\": [evt]}  # deltas only (merged)\n","\n","print(\"Cell 3 ready: parallel-safe state + AgentNode.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fEyhkhFiDAWx","executionInfo":{"status":"ok","timestamp":1771456697097,"user_tz":360,"elapsed":44,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"29785ad5-c7d0-42bc-df31-2c9035fb98bb"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Cell 3 ready: parallel-safe state + AgentNode.\n"]}]},{"cell_type":"markdown","source":["##4.SYNTHETIC PORTFOLIO"],"metadata":{"id":"7CdFvriyiHh-"}},{"cell_type":"markdown","source":["###4.1.OVERVIEW"],"metadata":{"id":"r7AlxPj_iI11"}},{"cell_type":"markdown","source":["**CELL 4/10 — Synthetic portfolio and synthetic snapshot (fast and deterministic)**\n","\n","Cell 4 creates the “world” the system will operate on. We use synthetic data on purpose. In a teaching setting, external market data introduces noise, API failures, and hidden assumptions. Synthetic data lets us control the environment and focus on architecture. The objective is not realism in prices; the objective is realism in workflow structure.\n","\n","We generate a fixed universe of tickers and random starting weights. Because we set a seed, every run produces the same starting portfolio. That is important because it makes comparisons meaningful. If the portfolio changes randomly between runs, students can’t tell whether differences come from the architecture or the inputs.\n","\n","Then we create a synthetic market snapshot with three features per asset: **risk**, **cost**, and **signal**. These map directly to the committee perspectives in this notebook. Risk is treated as “higher is worse” (think volatility proxy). Cost is treated as “higher is worse” (think impact or slippage proxy). Signal is treated as “higher is better” (think alpha or score proxy). These are not full finance models, but they are enough to create a real tension: the asset with the best signal might also be costly to trade, and the asset with the lowest risk might have a weak signal.\n","\n","We also define constraints and a simple policy stub. Constraints include max weight, min weight, a turnover cap, and a minimum trade size. These constraints are what turns “a suggestion” into “an implementable plan.” In real portfolio work, constraints are not optional. Without them, you are writing fiction.\n","\n","The design choice here is very intentional: the LLM will propose trades, but the deterministic reducer will enforce constraints. That division of labor is only meaningful if constraints exist and are explicit. Cell 4 is therefore the first half of the “control story”: it creates the portfolio and the rules of the game.\n","\n","This cell is also optimized for speed. Everything runs instantly. That matters because the architecture depends on quick iteration. Students should be able to rerun the process, adjust parameters like turnover cap, and observe how the workflow responds, without waiting for heavy computations.\n"],"metadata":{"id":"ueNd8fXviKfV"}},{"cell_type":"markdown","source":["###4.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"WYXG5UW3iK2O"}},{"cell_type":"code","source":["# CELL 4/10 — Synthetic portfolio + synthetic market snapshot (fast, classroom-safe)\n","\n","def make_synthetic_portfolio(seed: int = 7) -> Tuple[List[str], Dict[str, float]]:\n","    rnd = random.Random(seed)\n","    universe = [\"AAPL\", \"MSFT\", \"NVDA\", \"AMZN\", \"GOOGL\", \"JPM\", \"XOM\", \"UNH\"]\n","    raw = [rnd.random() for _ in universe]\n","    s = sum(raw)\n","    w = {a: v / s for a, v in zip(universe, raw)}\n","    return universe, w\n","\n","def make_synthetic_snapshot(universe: List[str], seed: int = 7) -> Dict[str, Any]:\n","    rnd = random.Random(seed + 101)\n","    snap: Dict[str, Any] = {\"features\": {}}\n","    for a in universe:\n","        # risk: higher is worse; cost: higher is worse; signal: higher is better\n","        risk = round(0.10 + 0.35 * rnd.random(), 4)     # proxy: vol\n","        cost = round(0.0005 + 0.004 * rnd.random(), 5)  # proxy: impact per 1.0 turnover\n","        signal = round(-1.0 + 2.0 * rnd.random(), 4)    # proxy: z-score alpha\n","        snap[\"features\"][a] = {\"risk\": risk, \"cost\": cost, \"signal\": signal}\n","    return snap\n","\n","def default_constraints() -> Dict[str, Any]:\n","    return {\n","        \"max_weight\": 0.22,\n","        \"min_weight\": 0.00,\n","        \"turnover_cap\": 0.35,         # L1 turnover cap on sum(|dw|)\n","        \"min_trade_abs\": 0.0025,      # prune tiny trades\n","    }\n","\n","def default_policy() -> Dict[str, Any]:\n","    return {\"type\": \"tilt_equal_weight\", \"tilt_strength\": 0.22}\n","\n","u, h = make_synthetic_portfolio(CONFIG[\"seed\"])\n","snap = make_synthetic_snapshot(u, CONFIG[\"seed\"])\n","print(\"Universe:\", u)\n","print(\"Holdings sum:\", round(sum(h.values()), 8))\n","print(\"Sample features:\", {k: snap[\"features\"][k] for k in u[:3]})\n"],"metadata":{"id":"zwXf8QYdjSeI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771456217369,"user_tz":360,"elapsed":8,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"f84f0f38-fb0c-4897-f96e-fe63e0f4f422"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Universe: ['AAPL', 'MSFT', 'NVDA', 'AMZN', 'GOOGL', 'JPM', 'XOM', 'UNH']\n","Holdings sum: 1.0\n","Sample features: {'AAPL': {'risk': 0.1457, 'cost': 0.00376, 'signal': 0.7609}, 'MSFT': {'risk': 0.2348, 'cost': 0.00161, 'signal': -0.6082}, 'NVDA': {'risk': 0.1283, 'cost': 0.00136, 'signal': -0.596}}\n"]}]},{"cell_type":"markdown","source":["##5.LLM WRAPPER"],"metadata":{"id":"PJydwmXniOfj"}},{"cell_type":"markdown","source":["###5.1.OVERVIEW"],"metadata":{"id":"MeZ0d501iP49"}},{"cell_type":"markdown","source":["**CELL 5/10 — LLM wrapper (minimal, correct API shape, governance-friendly)**\n","\n","Cell 5 is where the notebook becomes genuinely agentic: it can call the LLM. The most important thing to understand is that we are not using a large framework with hidden memory. We are using a minimal HTTP client with explicit inputs. That is deliberate. In finance, you want to reduce hidden behavior. “Magic” clients that silently store context or adjust prompts are convenient, but they make audits hard.\n","\n","This wrapper enforces three critical controls. First, it retrieves the API key using `userdata.get(\"ANTHROPIC_API_KEY\")` in all caps. That’s the Colab secret mechanism. The notebook refuses to run if the key is missing. Silent fallbacks are dangerous because they can lead to confusing “why did it fail?” moments.\n","\n","Second, the wrapper uses the correct Messages API shape: **system is a top-level field**, and `messages` includes only user/assistant roles. This matters because incorrect request shape is a common source of 400 errors. This is not “complexity for complexity’s sake.” It is a correctness fix.\n","\n","Third, we keep the wrapper small and testable. It takes `system`, `user_content`, model name, temperature, and max tokens. It returns plain text. That’s it. No tool calls, no streaming, no retries. This is a classroom notebook; we prefer clarity over feature volume.\n","\n","Finally, we include a strict JSON extraction helper. The committee nodes are instructed to output JSON only, but models sometimes add extra text. The parser searches for a `{...}` block and parses it. If no JSON is found, it raises an error, which will be caught by `AgentNode` and written into state. That is governance: failures become visible state, not hidden exceptions.\n","\n","So Cell 5 defines the “LLM as a controlled tool.” It is not a conversational partner. It is a service that returns a structured proposal, and every call is explicit, parameterized, and auditable.\n"],"metadata":{"id":"WY3hc3q2iSKx"}},{"cell_type":"markdown","source":["###5.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"fzeMhbzgiShs"}},{"cell_type":"code","source":["# CELL 5/10 — Minimal Anthropic Messages API wrapper (correct request shape) + safe JSON extraction\n","\n","def get_api_key() -> str:\n","    key = userdata.get(\"ANTHROPIC_API_KEY\")  # ALL CAPS, required\n","    if not key or not isinstance(key, str):\n","        raise RuntimeError('Missing Colab secret: userdata.get(\"ANTHROPIC_API_KEY\")')\n","    return key.strip()\n","\n","def anthropic_text(*,\n","                   system: str,\n","                   user_content: str,\n","                   model: str,\n","                   temperature: float,\n","                   max_tokens: int) -> str:\n","    \"\"\"\n","    Minimal HTTP call to Anthropic /v1/messages.\n","\n","    IMPORTANT:\n","    - 'system' is a TOP-LEVEL field in the payload (not a message role).\n","    - messages contain only user/assistant roles.\n","    \"\"\"\n","    headers = {\n","        \"x-api-key\": get_api_key(),\n","        \"anthropic-version\": \"2023-06-01\",\n","        \"content-type\": \"application/json\",\n","    }\n","\n","    payload = {\n","        \"model\": model,\n","        \"max_tokens\": int(max_tokens),\n","        \"temperature\": float(temperature),\n","        \"system\": system,\n","        \"messages\": [{\"role\": \"user\", \"content\": user_content}],\n","    }\n","\n","    with httpx.Client(timeout=45.0) as client:\n","        r = client.post(\"https://api.anthropic.com/v1/messages\", headers=headers, json=payload)\n","        r.raise_for_status()\n","        data = r.json()\n","\n","    parts = data.get(\"content\", [])\n","    text = \"\".join([p.get(\"text\", \"\") for p in parts if p.get(\"type\") == \"text\"])\n","    return text\n","\n","_JSON_BLOCK_RE = re.compile(r\"\\{.*\\}\", re.DOTALL)\n","\n","def parse_json_from_text(text: str) -> Dict[str, Any]:\n","    \"\"\"\n","    Strict-ish JSON extraction: find the first {...} block and parse.\n","    \"\"\"\n","    m = _JSON_BLOCK_RE.search(text)\n","    if not m:\n","        raise ValueError(\"No JSON object found in model output.\")\n","    return json.loads(m.group(0))\n","\n","print(\"Cell 5 ready: Anthropic wrapper uses top-level system field.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rn6RQoz-K6-_","executionInfo":{"status":"ok","timestamp":1771458772659,"user_tz":360,"elapsed":65,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"883e37df-7a21-4bc0-de62-161f3e01cf27"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Cell 5 ready: Anthropic wrapper uses top-level system field.\n"]}]},{"cell_type":"markdown","source":["##6.AGENT NODES"],"metadata":{"id":"3qMrcRA8iVGP"}},{"cell_type":"markdown","source":["###6.1.OVERVIEW"],"metadata":{"id":"3Ak9KwaQiXOz"}},{"cell_type":"markdown","source":["**CELL 6/10 — Agent nodes (human team roles encoded as functions)**\n","\n","Cell 6 is where the narrative becomes concrete: we define the nodes that behave like members of a rebalance team. The intake node is like the operations associate assembling the pack: it ensures the state contains the portfolio universe, current holdings, constraints, policy, and market snapshot. It also initializes the mergeable lists (`committee_reports`, `errors`, `trace`) to empty lists at the start of a run or round. This matters because mergeable channels should start clean; otherwise you mix reports from different rounds.\n","\n","The committee_member node is the key “LLM usage” node. It represents one human analyst with a single mandate. We do not ask the model to do everything. We ask it to propose trades under one perspective: risk, cost, or signal. The prompt is structured, includes the holdings, the features, the constraints, and an output schema. The model must return strict JSON. We also print `[LLM CALL]` and a short preview of raw output so students can see the call happened.\n","\n","The reducer node is the portfolio manager’s discipline. It does not call the LLM. It takes the committee reports and merges them deterministically using fixed weights across perspectives. Then it enforces constraints: clipping to max/min weights, normalizing, pruning tiny trades, and scaling trades if turnover exceeds the cap. This is the governance principle: proposals may be “creative,” but the final plan must be mechanically feasible.\n","\n","The gate node is the committee chair. It checks for errors first. If errors exist, we escalate to HUMAN_REVIEW. If no errors, it checks disagreement. If disagreement is high and rounds remain, it triggers a bounded rerun. Otherwise it approves. This creates a controlled stopping rule: no infinite debates, no infinite loops.\n","\n","So Cell 6 encodes a real team: intake, three analysts, a portfolio manager aggregator, and a chair who decides when to stop. It is not “prompt engineering.” It is **organizational design expressed as a state machine**.\n"],"metadata":{"id":"Fnhd7Fwaicyv"}},{"cell_type":"markdown","source":["###6.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"0jFxOakbido7"}},{"cell_type":"code","source":["# CELL 6/10 — Agent nodes: intake -> MAP (parallel committee) -> REDUCE (aggregation) -> gate -> END\n","# (Parallel-safe merge channels + explicit LLM visibility in committee_member; uses corrected Cell 5 wrapper)\n","\n","def intake_fn(state: RebalanceState) -> Dict[str, Any]:\n","    \"\"\"\n","    Intake initializes deterministic run metadata and synthetic inputs (if absent).\n","    NOTE: We initialize merge-channel lists explicitly as empty lists.\n","    \"\"\"\n","    run_id = state.get(\"run_id\") or str(uuid.uuid4())\n","\n","    base: RebalanceState = {\n","        \"run_id\": run_id,\n","        \"ts_utc\": utc_now(),\n","        \"config\": CONFIG,\n","        \"versions\": VERSIONS,\n","        \"round\": int(state.get(\"round\", 1)),\n","        \"committee_perspectives\": list(CONFIG[\"committee_perspectives\"]),\n","        \"committee_expected\": len(CONFIG[\"committee_perspectives\"]),\n","        \"committee_reports\": [],  # merged list, start empty each round\n","        \"errors\": [],             # merged list, start empty each round\n","        \"trace\": [],              # merged list, start empty each round\n","    }\n","\n","    # attach synthetic inputs if not present\n","    if \"universe\" not in state:\n","        u, h = make_synthetic_portfolio(CONFIG[\"seed\"])\n","        base[\"universe\"] = u\n","        base[\"holdings\"] = h\n","        base[\"constraints\"] = default_constraints()\n","        base[\"target_policy\"] = default_policy()\n","        base[\"market_snapshot\"] = make_synthetic_snapshot(u, CONFIG[\"seed\"])\n","    else:\n","        for k in [\"universe\", \"holdings\", \"constraints\", \"target_policy\", \"market_snapshot\"]:\n","            if k in state:\n","                base[k] = state[k]\n","\n","    return base\n","\n","intake = AgentNode(\"intake\", intake_fn)\n","\n","def committee_member_fn(state: RebalanceState) -> Dict[str, Any]:\n","    \"\"\"\n","    One committee member (perspective) proposes delta-weights under constraints.\n","    Returns a ONE-ELEMENT list for committee_reports so parallel branches can merge via operator.add.\n","    \"\"\"\n","    perspective = state.get(\"committee_current_perspective\")\n","    if perspective not in CONFIG[\"committee_perspectives\"]:\n","        raise ValueError(\"Invalid or missing committee_current_perspective\")\n","\n","    holdings = state[\"holdings\"]\n","    feats = state[\"market_snapshot\"][\"features\"]\n","    policy = state[\"target_policy\"]\n","    cons = state[\"constraints\"]\n","\n","    sys = \"You are a portfolio rebalance committee member. Output STRICT JSON only. No prose outside JSON.\"\n","    user_obj = {\n","        \"task\": \"Propose delta-weights (trades) under your assigned perspective, consistent with constraints.\",\n","        \"perspective\": perspective,\n","        \"holdings\": holdings,\n","        \"features\": feats,\n","        \"policy\": policy,\n","        \"constraints\": cons,\n","        \"output_schema\": {\n","            \"perspective\": \"risk|cost|signal\",\n","            \"proposed_trades\": {\"TICKER\": \"delta_weight_float\"},\n","            \"notes\": \"short string\",\n","            \"metrics\": {\"turnover\": \"float\", \"top_changes\": [\"TICKER\", \"...\"]},\n","        },\n","        \"rules\": [\n","            \"Return STRICT JSON only.\",\n","            \"Sum of trades should be ~0 (self-financing).\",\n","            \"Respect max_weight/min_weight after applying trades.\",\n","            \"Keep turnover reasonable; aggregator will enforce hard cap.\",\n","            \"If unsure, return smaller trades.\",\n","        ],\n","    }\n","\n","    # --- visibility: prove the LLM is called per parallel branch ---\n","    print(f\"[LLM CALL] committee_member perspective={perspective} model={CONFIG['model']}\")\n","\n","    txt = anthropic_text(\n","        system=sys,\n","        user_content=json.dumps(user_obj, ensure_ascii=False),\n","        model=CONFIG[\"model\"],\n","        temperature=CONFIG[\"temperature\"],\n","        max_tokens=CONFIG[\"max_tokens\"],\n","    )\n","\n","    print(f\"[LLM RAW PREVIEW] {perspective}:\", txt[:220].replace(\"\\n\", \" \"), \"...\")\n","\n","    report = parse_json_from_text(txt)\n","    report[\"perspective\"] = perspective\n","\n","    if \"proposed_trades\" not in report or not isinstance(report[\"proposed_trades\"], dict):\n","        raise ValueError(\"committee report missing proposed_trades dict\")\n","\n","    return {\"committee_reports\": [report]}  # delta list (merged)\n","\n","committee_member = AgentNode(\"committee_member\", committee_member_fn)\n","\n","def reduce_fn(state: RebalanceState) -> Dict[str, Any]:\n","    \"\"\"\n","    Aggregation:\n","      - Combine committee proposals using deterministic weights\n","      - Enforce constraints (max/min weights, turnover cap)\n","      - Score disagreement for a bounded stability rerun\n","    \"\"\"\n","    reports = state.get(\"committee_reports\", [])\n","    expected = int(state[\"committee_expected\"])\n","\n","    if len(reports) < expected:\n","        return {}  # not ready yet\n","\n","    universe = state[\"universe\"]\n","    holdings = state[\"holdings\"]\n","    cons = state[\"constraints\"]\n","\n","    w = {\"risk\": 0.40, \"cost\": 0.25, \"signal\": 0.35}\n","\n","    per: Dict[str, Dict[str, float]] = {}\n","    for r in reports:\n","        p = str(r.get(\"perspective\", \"\"))\n","        vec = {k: float(v) for k, v in r.get(\"proposed_trades\", {}).items()}\n","        per[p] = vec\n","    for p in CONFIG[\"committee_perspectives\"]:\n","        per.setdefault(p, {})\n","\n","    agg: Dict[str, float] = {a: 0.0 for a in universe}\n","    for p in CONFIG[\"committee_perspectives\"]:\n","        wp = float(w.get(p, 0.0))\n","        for a in universe:\n","            agg[a] += wp * float(per[p].get(a, 0.0))\n","\n","    s = sum(agg.values())\n","    if abs(s) > 1e-12:\n","        adj = s / len(universe)\n","        for a in universe:\n","            agg[a] -= adj\n","\n","    min_abs = float(cons[\"min_trade_abs\"])\n","    for a in universe:\n","        if abs(agg[a]) < min_abs:\n","            agg[a] = 0.0\n","\n","    max_w = float(cons[\"max_weight\"])\n","    min_w = float(cons[\"min_weight\"])\n","\n","    def clip_and_norm(weights: Dict[str, float]) -> Dict[str, float]:\n","        clipped = {a: min(max(weights[a], min_w), max_w) for a in universe}\n","        tot = sum(clipped.values())\n","        if tot <= 0:\n","            ew = 1.0 / len(universe)\n","            return {a: ew for a in universe}\n","        return {a: clipped[a] / tot for a in universe}\n","\n","    post = {a: holdings[a] + agg[a] for a in universe}\n","    post = clip_and_norm(post)\n","    trades = {a: post[a] - holdings[a] for a in universe}\n","\n","    turnover = sum(abs(trades[a]) for a in universe)\n","    cap = float(cons[\"turnover_cap\"])\n","    scale = 1.0\n","    if turnover > cap and turnover > 1e-12:\n","        scale = cap / turnover\n","        trades = {a: trades[a] * scale for a in universe}\n","        post2 = {a: holdings[a] + trades[a] for a in universe}\n","        post2 = clip_and_norm(post2)\n","        trades = {a: post2[a] - holdings[a] for a in universe}\n","        turnover = sum(abs(trades[a]) for a in universe)\n","\n","    aligned = []\n","    for p in CONFIG[\"committee_perspectives\"]:\n","        aligned.append({a: float(per[p].get(a, 0.0)) for a in universe})\n","\n","    d = []\n","    for i in range(len(aligned)):\n","        for j in range(i + 1, len(aligned)):\n","            d.append(sum(abs(aligned[i][a] - aligned[j][a]) for a in universe))\n","    disagreement = float(sum(d) / max(1, len(d)))\n","\n","    scores = {\n","        \"turnover\": float(turnover),\n","        \"turnover_cap\": cap,\n","        \"turnover_scale\": float(scale),\n","        \"disagreement_l1_avg\": disagreement,\n","        \"expected_reports\": expected,\n","        \"received_reports\": len(reports),\n","    }\n","\n","    return {\"proposed_trades\": trades, \"committee_scores\": scores}\n","\n","reduce_node = AgentNode(\"committee_reduce\", reduce_fn)\n","\n","def gate_fn(state: RebalanceState) -> Dict[str, Any]:\n","    \"\"\"\n","    Decision gate:\n","      - if any errors -> HUMAN_REVIEW\n","      - if high disagreement and rounds remaining -> rerun once (bounded)\n","      - else APPROVE\n","    \"\"\"\n","    errs = state.get(\"errors\", [])\n","    scores = state.get(\"committee_scores\", {})\n","    disagreement = float(scores.get(\"disagreement_l1_avg\", 0.0))\n","    r = int(state.get(\"round\", 1))\n","\n","    if errs:\n","        decision = {\n","            \"status\": \"HUMAN_REVIEW\",\n","            \"reason\": \"Errors encountered in committee workflow.\",\n","            \"errors\": errs[:10],\n","            \"scores\": scores,\n","        }\n","        return {\"rebalance_decision\": decision, \"final_decision\": \"HUMAN_REVIEW\"}\n","\n","    if disagreement >= float(CONFIG[\"disagreement_threshold\"]) and r < int(CONFIG[\"max_rounds\"]):\n","        decision = {\n","            \"status\": \"HUMAN_REVIEW\",\n","            \"reason\": \"High committee disagreement; rerun once for stability (bounded).\",\n","            \"scores\": scores,\n","            \"next_round\": r + 1,\n","        }\n","        return {\"rebalance_decision\": decision, \"final_decision\": \"HUMAN_REVIEW\", \"round\": r + 1}\n","\n","    decision = {\n","        \"status\": \"APPROVE\",\n","        \"reason\": \"Committee aggregated proposal meets constraints; disagreement within threshold.\",\n","        \"scores\": scores,\n","        \"proposed_trades\": state.get(\"proposed_trades\", {}),\n","        \"notes\": \"Trades are delta-weights; execution planning is out of scope for N6.\",\n","    }\n","    return {\"rebalance_decision\": decision, \"final_decision\": \"APPROVE\"}\n","\n","gate = AgentNode(\"gate\", gate_fn)\n","\n","print(\"Cell 6 ready: intake + committee_member(LLM) + reduce + gate.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_mH5tpNjLBj6","executionInfo":{"status":"ok","timestamp":1771458798740,"user_tz":360,"elapsed":29,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"556230f8-5cd9-468c-909e-a4dbb90b50ff"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Cell 6 ready: intake + committee_member(LLM) + reduce + gate.\n"]}]},{"cell_type":"markdown","source":["##7.BUILDING THE GRAPH"],"metadata":{"id":"hnqxNRdOigzp"}},{"cell_type":"markdown","source":["###7.1.OVERVIEW"],"metadata":{"id":"9N3hP5ksikQZ"}},{"cell_type":"markdown","source":["**CELL 7/10 — Building the graph (the topology is the lesson)**\n","\n","Cell 7 turns the nodes into a real workflow using LangGraph. This is where the notebook earns its title: “parallel committee + aggregation.” The topology is not incidental. It is the teaching artifact.\n","\n","We start with a `fanout_router` that returns a list of `Send` objects. Each Send targets the committee_member node and carries a payload. The important lesson from your debugging is that parallel branches must receive the full state snapshot. If you send only the “perspective” field, the committee_member node will not have holdings, constraints, or anything else. So the router creates a payload from the current state and adds `committee_current_perspective`. That is how we simulate “same pack, different analyst.”\n","\n","Then we connect the flow: intake -> fanout -> committee_member -> committee_reduce -> gate -> END. The merge behavior happens automatically because we declared merge channels in the state schema. When three committee_member branches finish, their updates to `committee_reports` are concatenated into one list in the shared state. That is the map-reduce pattern in action.\n","\n","The gate has conditional routing. If it decides to rerun (based on disagreement and round), it loops back to intake. The loop is bounded by `max_rounds`. That boundedness is not optional; it is a hard control.\n","\n","Finally, we compile the graph and render it with Mermaid. The diagram must match the topology exactly. This is a governance requirement: the executed process must be visible. In regulated environments, it’s the difference between “we think the process works” and “here is the exact workflow that ran.”\n","\n","Cell 7 therefore is the bridge from functions to system. It’s where the architecture becomes a topology you can inspect, teach, and audit.\n"],"metadata":{"id":"MzaMhrkuimFO"}},{"cell_type":"markdown","source":["###7.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"epotbIpqimYU"}},{"cell_type":"code","source":["# CELL 7/10 — Build LangGraph topology (parallel MAP via Send) + compile + visualize\n","# (FIXED: Send payload includes the FULL current state so branches never miss keys)\n","\n","from langgraph.types import Send  # fan-out primitive\n","\n","def fanout_router(state: RebalanceState) -> List[Send]:\n","    sends: List[Send] = []\n","    for p in CONFIG[\"committee_perspectives\"]:\n","        payload = dict(state)  # IMPORTANT: branch receives full state snapshot\n","        payload[\"committee_current_perspective\"] = p\n","        sends.append(Send(\"committee_member\", payload))\n","    return sends\n","\n","def gate_router(state: RebalanceState) -> str:\n","    dec = state.get(\"rebalance_decision\", {}).get(\"status\")\n","    if dec == \"HUMAN_REVIEW\" and not state.get(\"errors\"):\n","        if int(state.get(\"round\", 1)) > 1 and int(state.get(\"round\", 1)) <= int(CONFIG[\"max_rounds\"]):\n","            return \"fanout\"\n","    return \"end\"\n","\n","graph = StateGraph(RebalanceState)\n","\n","graph.add_node(\"intake\", intake)\n","graph.add_node(\"committee_member\", committee_member)\n","graph.add_node(\"committee_reduce\", reduce_node)\n","graph.add_node(\"gate\", gate)\n","\n","graph.set_entry_point(\"intake\")\n","\n","graph.add_conditional_edges(\"intake\", fanout_router, [\"committee_member\"])\n","graph.add_edge(\"committee_member\", \"committee_reduce\")\n","graph.add_edge(\"committee_reduce\", \"gate\")\n","graph.add_conditional_edges(\"gate\", gate_router, {\"fanout\": \"intake\", \"end\": END})\n","\n","compiled = graph.compile()\n","\n","mmd = display_langgraph_mermaid(compiled)\n","print(\"Mermaid chars:\", len(mmd))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":622},"id":"UkG1nd_OKV56","executionInfo":{"status":"ok","timestamp":1771458801483,"user_tz":360,"elapsed":24,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"491de631-9fde-48e1-acc1-bffa9d777432"},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<div style=\"border:1px solid rgba(0,0,0,0.12); border-radius:12px; padding:12px; overflow:auto; height:560px;\">\n","  <div id=\"mmd-5855986\" class=\"mermaid\">\n","%%{init: {'flowchart': {'curve': 'linear'}}}%%\n","graph TD;\n","\t__start__([&lt;p&gt;__start__&lt;/p&gt;]):::first\n","\tintake(intake)\n","\tcommittee_member(committee_member)\n","\tcommittee_reduce(committee_reduce)\n","\tgate(gate)\n","\t__end__([&lt;p&gt;__end__&lt;/p&gt;]):::last\n","\t__start__ --&gt; intake;\n","\tcommittee_member --&gt; committee_reduce;\n","\tcommittee_reduce --&gt; gate;\n","\tintake -.-&gt; committee_member;\n","\tgate -. &amp;nbsp;fanout&amp;nbsp; .-&gt; intake;\n","\tgate -. &amp;nbsp;end&amp;nbsp; .-&gt; __end__;\n","\tclassDef default fill:#f2f0ff,line-height:1.2\n","\tclassDef first fill-opacity:0\n","\tclassDef last fill:#bfb6fc\n","\n","  </div>\n","</div>\n","\n","<script type=\"module\">\n","  import mermaid from \"https://unpkg.com/mermaid@10.6.1/dist/mermaid.esm.min.mjs\";\n","  mermaid.initialize({\n","    startOnLoad: false,\n","    securityLevel: \"strict\",\n","    theme: \"default\",\n","    flowchart: { curve: \"linear\" },\n","    maxTextSize: 200000\n","  });\n","  const el = document.getElementById(\"mmd-5855986\");\n","  const code = el.textContent;\n","  const { svg } = await mermaid.render(\"mmd-5855986-svg\", code);\n","  el.innerHTML = svg;\n","</script>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Mermaid chars: 536\n"]}]},{"cell_type":"markdown","source":["##8.EXECUTION"],"metadata":{"id":"BLus531lirIL"}},{"cell_type":"markdown","source":["###8.1.OVERVIEW"],"metadata":{"id":"x0j2JYTnixuf"}},{"cell_type":"markdown","source":["**CELL 8/10 — Execution (what happens when the system runs)**\n","\n","Cell 8 is where the system becomes “alive.” We create an initial state and invoke the compiled graph. The key concept is that the state is not just inputs; it is the evolving record of the process. We initialize the governance fields: run_id, timestamps, config, versions, round, and the mergeable lists. We also include committee metadata (perspectives, expected report count, empty report list). This makes the run self-contained and explicit.\n","\n","When execution starts, intake ensures the portfolio and snapshot exist. Then the graph fans out into three parallel committee_member calls. In the notebook output, you see three `[LLM CALL]` lines. That is the “human team” metaphor made visible: three analysts working at the same time.\n","\n","Each committee_member returns a report. Those reports merge into `committee_reports`. Then committee_reduce runs once with the merged list. It produces deterministic `proposed_trades` and `committee_scores`. Those scores include turnover and disagreement. Then gate uses those scores to decide: approve, reject, or human review. If the system is stable and no errors occur, approval is typical. If the LLM fails, parsing fails, or disagreement is high, the gate escalates. That escalation is not a bug. It is a governance behavior: the system is allowed to stop safely.\n","\n","Cell 8 also prints the outputs in a way that is easy to inspect: final decision, round, scores, decision object, and top trades. This supports the pedagogical goal: students see both the process and the result. They do not have to dig through hidden logs.\n","\n","Execution here is not “trading.” It is a controlled simulation of the rebalance decision workflow. The deliverable is a proposed trade vector and a decision status, not an execution report. That boundary is intentional: execution belongs in later notebooks and different architectures.\n","\n","So Cell 8 teaches the main operational lesson: agentic workflows are not text outputs. They are **state transitions through a graph**, with explicit stopping conditions and visible intermediate artifacts.\n"],"metadata":{"id":"CGJ3TUQwi2JO"}},{"cell_type":"markdown","source":["###8.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"SCv1wHOni2cy"}},{"cell_type":"code","source":["# CELL 8/10 — Execute graph (single run) + inspect outputs\n","# (Now works because committee branches receive full state via Send payload)\n","\n","initial_state: RebalanceState = {\n","    \"run_id\": str(uuid.uuid4()),\n","    \"ts_utc\": utc_now(),\n","    \"config\": CONFIG,\n","    \"versions\": VERSIONS,\n","    \"round\": 1,\n","\n","    # include committee metadata explicitly\n","    \"committee_perspectives\": list(CONFIG[\"committee_perspectives\"]),\n","    \"committee_expected\": len(CONFIG[\"committee_perspectives\"]),\n","    \"committee_reports\": [],\n","\n","    # merge-channel lists start empty\n","    \"errors\": [],\n","    \"trace\": [],\n","}\n","\n","final_state: RebalanceState = compiled.invoke(initial_state)\n","\n","print(\"FINAL_DECISION:\", final_state.get(\"final_decision\"))\n","print(\"ROUND:\", final_state.get(\"round\"))\n","print(\"SCORES:\", json.dumps(final_state.get(\"committee_scores\", {}), indent=2))\n","print(\"DECISION:\", json.dumps(final_state.get(\"rebalance_decision\", {}), indent=2))\n","\n","tr = final_state.get(\"proposed_trades\", {})\n","if tr:\n","    top = sorted(tr.items(), key=lambda kv: abs(float(kv[1])), reverse=True)[:8]\n","    print(\"TOP TRADES (abs):\", top)\n","\n","print(\"REPORTS_RECEIVED:\", len(final_state.get(\"committee_reports\", [])))\n","print(\"TRACE_LEN:\", len(final_state.get(\"trace\", [])))\n","print(\"ERRORS:\", final_state.get(\"errors\", []))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VZUcXPOnKabA","executionInfo":{"status":"ok","timestamp":1771458812006,"user_tz":360,"elapsed":7177,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"0de53ea5-108d-4e23-9746-784c565ba28d"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["[LLM CALL] committee_member perspective=risk model=claude-haiku-4-5-20251001\n","[LLM CALL] committee_member perspective=cost model=claude-haiku-4-5-20251001\n","[LLM CALL] committee_member perspective=signal model=claude-haiku-4-5-20251001\n","[LLM RAW PREVIEW] risk: ```json {   \"perspective\": \"risk\",   \"proposed_trades\": {     \"AAPL\": 0.0,     \"MSFT\": -0.0348,     \"NVDA\": 0.0,     \"AMZN\": -0.0272,     \"GOOGL\": -0.0425,     \"JPM\": -0.0137,     \"XOM\": 0.0282,     \"UNH\": 0.09   },   \"n ...\n","[LLM RAW PREVIEW] cost: ```json {   \"perspective\": \"cost\",   \"proposed_trades\": {     \"AAPL\": -0.01849,     \"MSFT\": 0.00839,     \"NVDA\": -0.02424,     \"AMZN\": 0.02282,     \"GOOGL\": -0.03607,     \"JPM\": -0.01221,     \"XOM\": 0.03327,     \"UNH\": 0 ...\n","[LLM RAW PREVIEW] signal: ```json {   \"perspective\": \"signal\",   \"proposed_trades\": {     \"AAPL\": 0.0275,     \"MSFT\": -0.0566,     \"NVDA\": -0.0850,     \"AMZN\": -0.0272,     \"GOOGL\": -0.0850,     \"JPM\": -0.0137,     \"XOM\": 0.0275,     \"UNH\": 0.052 ...\n","[LLM CALL] committee_member perspective=cost model=claude-haiku-4-5-20251001\n","[LLM CALL] committee_member perspective=signal model=claude-haiku-4-5-20251001\n","[LLM CALL] committee_member perspective=risk model=claude-haiku-4-5-20251001\n","[LLM RAW PREVIEW] signal: ```json {   \"perspective\": \"signal\",   \"proposed_trades\": {     \"AAPL\": 0.0275,     \"MSFT\": -0.0566,     \"NVDA\": -0.0850,     \"AMZN\": -0.0272,     \"GOOGL\": -0.0850,     \"JPM\": -0.0372,     \"XOM\": 0.0275,     \"UNH\": 0.036 ...\n","[LLM RAW PREVIEW] cost: ```json {   \"perspective\": \"cost\",   \"proposed_trades\": {     \"AAPL\": -0.01849,     \"MSFT\": 0.00839,     \"NVDA\": -0.02424,     \"AMZN\": 0.04782,     \"GOOGL\": -0.02108,     \"JPM\": -0.01722,     \"XOM\": 0.00327,     \"UNH\": 0 ...\n","[LLM RAW PREVIEW] risk: ```json {   \"perspective\": \"risk\",   \"proposed_trades\": {     \"AAPL\": 0.0,     \"MSFT\": -0.0348,     \"NVDA\": 0.0,     \"AMZN\": -0.0272,     \"GOOGL\": -0.0425,     \"JPM\": -0.0137,     \"XOM\": 0.0282,     \"UNH\": 0.09   },   \"n ...\n","FINAL_DECISION: APPROVE\n","ROUND: 2\n","SCORES: {\n","  \"turnover\": 0.1777259220562264,\n","  \"turnover_cap\": 0.35,\n","  \"turnover_scale\": 1.0,\n","  \"disagreement_l1_avg\": 0.30119999999999997,\n","  \"expected_reports\": 3,\n","  \"received_reports\": 6\n","}\n","DECISION: {\n","  \"status\": \"APPROVE\",\n","  \"reason\": \"Committee aggregated proposal meets constraints; disagreement within threshold.\",\n","  \"scores\": {\n","    \"turnover\": 0.1777259220562264,\n","    \"turnover_cap\": 0.35,\n","    \"turnover_scale\": 1.0,\n","    \"disagreement_l1_avg\": 0.30119999999999997,\n","    \"expected_reports\": 3,\n","    \"received_reports\": 6\n","  },\n","  \"proposed_trades\": {\n","    \"AAPL\": 0.01843301713375356,\n","    \"MSFT\": -0.02171568185001683,\n","    \"NVDA\": -0.019544638133250802,\n","    \"AMZN\": 0.0009405113702550746,\n","    \"GOOGL\": -0.03780939290279797,\n","    \"JPM\": -0.009793248142047628,\n","    \"XOM\": 0.03227999886809681,\n","    \"UNH\": 0.037209433656007734\n","  },\n","  \"notes\": \"Trades are delta-weights; execution planning is out of scope for N6.\"\n","}\n","TOP TRADES (abs): [('GOOGL', -0.03780939290279797), ('UNH', 0.037209433656007734), ('XOM', 0.03227999886809681), ('MSFT', -0.02171568185001683), ('NVDA', -0.019544638133250802), ('AAPL', 0.01843301713375356), ('JPM', -0.009793248142047628), ('AMZN', 0.0009405113702550746)]\n","REPORTS_RECEIVED: 6\n","TRACE_LEN: 12\n","ERRORS: []\n"]}]},{"cell_type":"markdown","source":["##9.AUDIT ARTIFACTS"],"metadata":{"id":"7JxS9vVQi4yB"}},{"cell_type":"markdown","source":["###9.1.0VERVIEW"],"metadata":{"id":"Wurgn_8fi5-m"}},{"cell_type":"markdown","source":["**CELL 9/10 — Audit artifacts (what makes this institutional, not a demo)**\n","\n","Cell 9 exports the required artifacts: `run_manifest.json`, `graph_spec.json`, and `final_state.json`. This is where the notebook becomes “audit-ready.” Without these files, you can show a cool demo, but you cannot support professional review. With these files, you can answer the questions that matter in finance: What ran? With what configuration? On what environment? What did it decide? Why did it stop?\n","\n","The run manifest captures run_id, timestamp, model lock, configuration, a hash of configuration (so you can detect changes), and an environment fingerprint (Python version, platform, library versions). This is similar to what a real desk might keep as a run record: it tells you the precise setup used to generate the recommendation. If someone changes a threshold later, the config hash changes. That’s governance by design.\n","\n","The graph spec captures the topology: nodes, edges, merge channels, bounded loop conditions, and the Mermaid diagram string. This is important because the topology is part of the “policy.” If a future version changes routing (for example, adds more committee members), the graph spec changes. You can then compare versions cleanly.\n","\n","The final state captures everything that happened: inputs, reports, trades, decision, errors, and trace events. The trace is especially important. It turns execution into an audit log: which nodes ran, how long they took, and whether they succeeded or failed. In regulated or institutional contexts, trace logs are the difference between “trust me” and “here is the record.”\n","\n","Cell 9 therefore is not an add-on. It is a core deliverable. It aligns directly with the project’s governance-first principle: every run produces inspectable evidence. The system is judged not only by output quality, but by **process quality**: reproducibility, reviewability, and accountability.\n"],"metadata":{"id":"SYflANI7irC5"}},{"cell_type":"markdown","source":["###9.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"WvgKf0NEi8Tj"}},{"cell_type":"code","source":["# CELL 9/10 — Audit artifacts (required): run_manifest.json + graph_spec.json + final_state.json\n","\n","def env_fingerprint() -> Dict[str, Any]:\n","    return {\n","        \"python\": platform.python_version(),\n","        \"platform\": platform.platform(),\n","        \"versions\": VERSIONS,\n","        \"cwd\": os.getcwd(),\n","    }\n","\n","def build_run_manifest(state: RebalanceState) -> Dict[str, Any]:\n","    cfg = dict(CONFIG)\n","    return {\n","        \"project\": cfg.get(\"project\"),\n","        \"notebook\": cfg.get(\"notebook\"),\n","        \"run_id\": state.get(\"run_id\"),\n","        \"ts_utc\": utc_now(),\n","        \"model_lock\": cfg.get(\"model\"),\n","        \"config\": cfg,\n","        \"config_hash_sha256\": stable_hash(cfg),\n","        \"env\": env_fingerprint(),\n","        \"notes\": [\n","            \"Synthetic-only inputs.\",\n","            \"Parallel committee MAP merges via Annotated[List, operator.add].\",\n","            \"All loops bounded by CONFIG['max_rounds'].\",\n","        ],\n","    }\n","\n","def build_graph_spec(mermaid: str) -> Dict[str, Any]:\n","    # We keep this spec explicit and topology-aligned with the code (auditable + stable).\n","    nodes = [\n","        {\"id\": \"intake\", \"type\": \"AgentNode\", \"role\": \"Initialize run + inputs\"},\n","        {\"id\": \"committee_member\", \"type\": \"AgentNode\", \"role\": \"LLM committee proposal (parallel MAP)\"},\n","        {\"id\": \"committee_reduce\", \"type\": \"AgentNode\", \"role\": \"Deterministic aggregation (REDUCE)\"},\n","        {\"id\": \"gate\", \"type\": \"AgentNode\", \"role\": \"Decision gate + bounded rerun or END\"},\n","        {\"id\": \"END\", \"type\": \"END\", \"role\": \"Explicit termination\"},\n","    ]\n","    edges = [\n","        {\"from\": \"intake\", \"to\": \"committee_member\", \"kind\": \"conditional_send_list\", \"fn\": \"fanout_router\"},\n","        {\"from\": \"committee_member\", \"to\": \"committee_reduce\", \"kind\": \"edge\"},\n","        {\"from\": \"committee_reduce\", \"to\": \"gate\", \"kind\": \"edge\"},\n","        {\"from\": \"gate\", \"to\": \"intake\", \"kind\": \"conditional\", \"label\": \"fanout\", \"fn\": \"gate_router\"},\n","        {\"from\": \"gate\", \"to\": \"END\", \"kind\": \"conditional\", \"label\": \"end\", \"fn\": \"gate_router\"},\n","    ]\n","    return {\n","        \"project\": CONFIG[\"project\"],\n","        \"notebook\": CONFIG[\"notebook\"],\n","        \"ts_utc\": utc_now(),\n","        \"mermaid\": mermaid,\n","        \"nodes\": nodes,\n","        \"edges\": edges,\n","        \"merge_channels\": {\n","            \"committee_reports\": \"Annotated[List[Dict], operator.add]\",\n","            \"errors\": \"Annotated[List[str], operator.add]\",\n","            \"trace\": \"Annotated[List[Dict], operator.add]\",\n","        },\n","        \"bounded_loop\": {\n","            \"max_rounds\": int(CONFIG[\"max_rounds\"]),\n","            \"loop_condition\": \"gate_router returns 'fanout' only when round>1 and round<=max_rounds and errors==[]\",\n","        },\n","    }\n","\n","# --- write required artifacts ---\n","if \"final_state\" not in globals() or not isinstance(final_state, dict):\n","    raise RuntimeError(\"final_state not found. Run CELL 8/10 successfully before exporting artifacts.\")\n","\n","if \"mmd\" not in globals() or not isinstance(mmd, str):\n","    # fallback: re-derive mermaid (still deterministic)\n","    mmd = compiled.get_graph().draw_mermaid()\n","\n","run_manifest = build_run_manifest(final_state)\n","graph_spec = build_graph_spec(mmd)\n","\n","write_json(\"run_manifest.json\", run_manifest)\n","write_json(\"graph_spec.json\", graph_spec)\n","write_json(\"final_state.json\", final_state)\n","\n","print(\"WROTE:\", [\"run_manifest.json\", \"graph_spec.json\", \"final_state.json\"])\n","print(\"run_id:\", final_state.get(\"run_id\"))\n","print(\"final_decision:\", final_state.get(\"final_decision\"))\n","print(\"reports_received:\", len(final_state.get(\"committee_reports\", [])))\n","print(\"errors_count:\", len(final_state.get(\"errors\", [])))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aYZLl8CjLdO4","executionInfo":{"status":"ok","timestamp":1771458912306,"user_tz":360,"elapsed":36,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"800ad365-4d0b-46ec-8000-75ec607dd5aa"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["WROTE: ['run_manifest.json', 'graph_spec.json', 'final_state.json']\n","run_id: af64cd1d-3bed-42cb-8905-ec61b74941ce\n","final_decision: APPROVE\n","reports_received: 6\n","errors_count: 0\n"]}]},{"cell_type":"markdown","source":["##10.AUDIT BUNDLE"],"metadata":{"id":"ss5L2x1ojA8d"}},{"cell_type":"markdown","source":["###10.1.OVERVIEW"],"metadata":{"id":"sduxTxx7jC0M"}},{"cell_type":"markdown","source":["**CELL 10/10 — Playground (bounded experimentation without changing topology)**\n","\n","Cell 10 is the controlled sandbox. The goal is to let students explore “what if” scenarios without changing the architecture. This is important: in professional practice, you often want to stress a process under different inputs before you rewrite it. You want to test robustness without introducing structural drift.\n","\n","The playground runs a few scenarios by changing synthetic inputs (seed) and constraints (turnover cap). The topology remains identical. That means any differences in outputs are caused by input conditions, not by code changes. This is a scientific attitude: keep structure fixed while varying conditions.\n","\n","The helper `summarize_state` prints a compact view: final decision, round, report count, error count, and key metrics like turnover and disagreement. This is how you teach interpretation. Students learn to read the outputs as a controlled record: was the system stable, did the committee disagree, did turnover binding occur?\n","\n","The helper `run_with_inputs` builds an initial state with explicit portfolio, snapshot, constraints, and governance fields. It then invokes the same compiled graph. This is also a good pattern for future notebooks: you can wrap the compiled graph behind a simple function that takes inputs and returns final state.\n","\n","The “bounded” principle still applies. We do not allow open-ended parameter sweeps that take minutes in class. We run a small number of scenarios quickly. That keeps the notebook usable under classroom time constraints and reinforces the discipline that experiments should be purposeful.\n","\n","Pedagogically, the playground is where students internalize the architecture: they see that the committee system is not brittle, that constraints shape outcomes, and that disagreements can trigger review. They also learn the deeper message: the value of the system is not just the trade vector. The value is a stable process that explains itself and produces artifacts.\n","\n","So Cell 10 closes the notebook in the right way: not with more features, but with a controlled way to learn by experimentation.\n"],"metadata":{"id":"bqPR0OmsWKLt"}},{"cell_type":"markdown","source":["###10.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"v_giRgoJjGY5"}},{"cell_type":"code","source":["# CELL 10/10 — Playground (bounded): run a few what-if scenarios without changing topology\n","\n","def summarize_state(tag: str, st: RebalanceState) -> None:\n","    scores = st.get(\"committee_scores\", {})\n","    print(\"\\n===\", tag, \"===\")\n","    print(\"final_decision:\", st.get(\"final_decision\"))\n","    print(\"round:\", st.get(\"round\"))\n","    print(\"reports_received:\", len(st.get(\"committee_reports\", [])))\n","    print(\"errors_count:\", len(st.get(\"errors\", [])))\n","    if scores:\n","        print(\"disagreement_l1_avg:\", scores.get(\"disagreement_l1_avg\"))\n","        print(\"turnover:\", scores.get(\"turnover\"), \"/\", scores.get(\"turnover_cap\"))\n","    tr = st.get(\"proposed_trades\", {})\n","    if tr:\n","        top = sorted(tr.items(), key=lambda kv: abs(float(kv[1])), reverse=True)[:5]\n","        print(\"top_trades_abs:\", top)\n","\n","def run_with_inputs(seed: int, *, turnover_cap: Optional[float] = None) -> RebalanceState:\n","    u, h = make_synthetic_portfolio(seed)\n","    snap = make_synthetic_snapshot(u, seed)\n","    cons = default_constraints()\n","    if turnover_cap is not None:\n","        cons = dict(cons)\n","        cons[\"turnover_cap\"] = float(turnover_cap)\n","\n","    init: RebalanceState = {\n","        \"run_id\": str(uuid.uuid4()),\n","        \"ts_utc\": utc_now(),\n","        \"config\": CONFIG,\n","        \"versions\": VERSIONS,\n","        \"round\": 1,\n","        \"committee_perspectives\": list(CONFIG[\"committee_perspectives\"]),\n","        \"committee_expected\": len(CONFIG[\"committee_perspectives\"]),\n","        \"committee_reports\": [],\n","        \"errors\": [],\n","        \"trace\": [],\n","        # provide full inputs so results vary by scenario deterministically\n","        \"universe\": u,\n","        \"holdings\": h,\n","        \"constraints\": cons,\n","        \"target_policy\": default_policy(),\n","        \"market_snapshot\": snap,\n","    }\n","    return compiled.invoke(init)\n","\n","# Scenario A: baseline synthetic inputs (seed=7)\n","st_a = run_with_inputs(7)\n","summarize_state(\"Scenario A (seed=7, default constraints)\", st_a)\n","\n","# Scenario B: different synthetic market (seed=21)\n","st_b = run_with_inputs(21)\n","summarize_state(\"Scenario B (seed=21, default constraints)\", st_b)\n","\n","# Scenario C: tighter turnover cap (seed=7, turnover_cap=0.12)\n","st_c = run_with_inputs(7, turnover_cap=0.12)\n","summarize_state(\"Scenario C (seed=7, tighter turnover_cap=0.12)\", st_c)\n","\n","print(\"\\nPlayground complete. Topology unchanged; only inputs/constraints varied.\")\n"],"metadata":{"id":"Lrqr5DdYjK83","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771458954502,"user_tz":360,"elapsed":25306,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"38eb989d-6313-47bc-df61-cc41196c3151"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["[LLM CALL] committee_member perspective=risk model=claude-haiku-4-5-20251001\n","[LLM CALL] committee_member perspective=cost model=claude-haiku-4-5-20251001\n","[LLM CALL] committee_member perspective=signal model=claude-haiku-4-5-20251001\n","[LLM RAW PREVIEW] risk: ```json {   \"perspective\": \"risk\",   \"proposed_trades\": {     \"AAPL\": 0.0,     \"MSFT\": -0.0348,     \"NVDA\": 0.0,     \"AMZN\": -0.0272,     \"GOOGL\": -0.0425,     \"JPM\": 0.0,     \"XOM\": 0.0,     \"UNH\": 0.1045   },   \"notes\" ...\n","[LLM RAW PREVIEW] cost: ```json {   \"perspective\": \"cost\",   \"proposed_trades\": {     \"AAPL\": -0.01849,     \"MSFT\": 0.00839,     \"NVDA\": -0.02424,     \"AMZN\": 0.04782,     \"GOOGL\": -0.03608,     \"JPM\": -0.01722,     \"XOM\": 0.00327,     \"UNH\": 0 ...\n","[LLM RAW PREVIEW] signal: ```json {   \"perspective\": \"signal\",   \"proposed_trades\": {     \"AAPL\": 0.0275,     \"MSFT\": -0.0566,     \"NVDA\": -0.0850,     \"AMZN\": -0.0272,     \"GOOGL\": -0.0850,     \"JPM\": -0.0137,     \"XOM\": 0.0275,     \"UNH\": 0.052 ...\n","[LLM CALL] committee_member perspective=risk model=claude-haiku-4-5-20251001\n","[LLM CALL] committee_member perspective=cost model=claude-haiku-4-5-20251001\n","[LLM CALL] committee_member perspective=signal model=claude-haiku-4-5-20251001\n","[LLM RAW PREVIEW] risk: ```json {   \"perspective\": \"risk\",   \"proposed_trades\": {     \"AAPL\": 0.0,     \"MSFT\": -0.0348,     \"NVDA\": -0.0259,     \"AMZN\": -0.0272,     \"GOOGL\": -0.0425,     \"JPM\": -0.0137,     \"XOM\": 0.0275,     \"UNH\": 0.0166   } ...\n","[LLM RAW PREVIEW] cost: ```json {   \"perspective\": \"cost\",   \"proposed_trades\": {     \"AAPL\": -0.01849,     \"MSFT\": 0.00839,     \"NVDA\": -0.02424,     \"AMZN\": 0.04782,     \"GOOGL\": -0.02108,     \"JPM\": -0.01722,     \"XOM\": 0.00327,     \"UNH\": 0 ...\n","[LLM RAW PREVIEW] signal: ```json {   \"perspective\": \"signal\",   \"proposed_trades\": {     \"AAPL\": 0.0275,     \"MSFT\": -0.0566,     \"NVDA\": -0.0850,     \"AMZN\": -0.0272,     \"GOOGL\": -0.0850,     \"JPM\": -0.0137,     \"XOM\": 0.0275,     \"UNH\": 0.052 ...\n","\n","=== Scenario A (seed=7, default constraints) ===\n","final_decision: APPROVE\n","round: 2\n","reports_received: 6\n","errors_count: 0\n","disagreement_l1_avg: 0.24955333333333332\n","turnover: 0.17872428583396874 / 0.35\n","top_trades_abs: [('GOOGL', -0.03793079154018847), ('XOM', 0.03415861415159485), ('UNH', 0.03245056724350853), ('NVDA', -0.03144490194151878), ('MSFT', -0.01915292948165874)]\n","[LLM CALL] committee_member perspective=risk model=claude-haiku-4-5-20251001\n","[LLM CALL] committee_member perspective=cost model=claude-haiku-4-5-20251001\n","[LLM CALL] committee_member perspective=signal model=claude-haiku-4-5-20251001\n","[LLM RAW PREVIEW] risk: ```json {   \"perspective\": \"risk\",   \"proposed_trades\": {     \"AAPL\": 0.0475,     \"MSFT\": -0.0525,     \"NVDA\": -0.0325,     \"AMZN\": -0.0175,     \"GOOGL\": -0.0425,     \"JPM\": 0.0225,     \"XOM\": -0.0150,     \"UNH\": 0.0900  ...\n","[LLM RAW PREVIEW] cost: ```json {   \"perspective\": \"cost\",   \"proposed_trades\": {     \"AAPL\": 0.0475,     \"MSFT\": -0.0125,     \"NVDA\": -0.0185,     \"AMZN\": 0.0225,     \"GOOGL\": 0.0325,     \"JPM\": -0.0385,     \"XOM\": -0.0275,     \"UNH\": 0.0025   ...\n","[LLM RAW PREVIEW] signal: ```json {   \"perspective\": \"signal\",   \"proposed_trades\": {     \"AAPL\": -0.0359,     \"MSFT\": 0.0285,     \"NVDA\": 0.0198,     \"AMZN\": -0.0087,     \"GOOGL\": -0.0225,     \"JPM\": -0.0172,     \"XOM\": -0.0168,     \"UNH\": 0.012 ...\n","[LLM CALL] committee_member perspective=risk model=claude-haiku-4-5-20251001\n","[LLM CALL] committee_member perspective=cost model=claude-haiku-4-5-20251001\n","[LLM CALL] committee_member perspective=signal model=claude-haiku-4-5-20251001\n","[LLM RAW PREVIEW] risk: ```json {   \"perspective\": \"risk\",   \"proposed_trades\": {     \"AAPL\": 0.0875,     \"MSFT\": -0.0425,     \"NVDA\": -0.0350,     \"AMZN\": -0.0225,     \"GOOGL\": -0.0550,     \"JPM\": -0.0175,     \"XOM\": -0.0425,     \"UNH\": -0.012 ...\n","[LLM RAW PREVIEW] cost: ```json {   \"perspective\": \"cost\",   \"proposed_trades\": {     \"AAPL\": 0.0475,     \"MSFT\": -0.0125,     \"NVDA\": -0.0185,     \"AMZN\": 0.0225,     \"GOOGL\": 0.0325,     \"JPM\": -0.0385,     \"XOM\": -0.0275,     \"UNH\": 0.0025   ...\n","[LLM RAW PREVIEW] signal: ```json {   \"perspective\": \"signal\",   \"proposed_trades\": {     \"AAPL\": -0.0250,     \"MSFT\": 0.0450,     \"NVDA\": 0.0380,     \"AMZN\": -0.0180,     \"GOOGL\": -0.0220,     \"JPM\": -0.0320,     \"XOM\": -0.0180,     \"UNH\": -0.00 ...\n","\n","=== Scenario B (seed=21, default constraints) ===\n","final_decision: APPROVE\n","round: 2\n","reports_received: 6\n","errors_count: 0\n","disagreement_l1_avg: 0.31066666666666665\n","turnover: 0.10803940760404587 / 0.35\n","top_trades_abs: [('AAPL', 0.0466377526933687), ('XOM', -0.021650051954633043), ('JPM', -0.01930023071947881), ('GOOGL', -0.013069421127911103), ('MSFT', 0.0041496965479577985)]\n","[LLM CALL] committee_member perspective=risk model=claude-haiku-4-5-20251001\n","[LLM CALL] committee_member perspective=cost model=claude-haiku-4-5-20251001\n","[LLM CALL] committee_member perspective=signal model=claude-haiku-4-5-20251001\n","[LLM RAW PREVIEW] cost: ```json {   \"perspective\": \"cost\",   \"proposed_trades\": {     \"AAPL\": -0.0125,     \"MSFT\": 0.0185,     \"NVDA\": -0.0220,     \"AMZN\": 0.0285,     \"GOOGL\": -0.0315,     \"JPM\": -0.0180,     \"XOM\": 0.0095,     \"UNH\": 0.0275   ...\n","[LLM RAW PREVIEW] signal: ```json {   \"perspective\": \"signal\",   \"proposed_trades\": {     \"AAPL\": 0.0275,     \"MSFT\": -0.0185,     \"NVDA\": -0.0220,     \"AMZN\": -0.0165,     \"GOOGL\": -0.0285,     \"JPM\": -0.0045,     \"XOM\": 0.0055,     \"UNH\": 0.057 ...\n","[LLM RAW PREVIEW] risk: ```json {   \"perspective\": \"risk\",   \"proposed_trades\": {     \"AAPL\": 0.0000,     \"MSFT\": -0.0250,     \"NVDA\": -0.0200,     \"AMZN\": -0.0272,     \"GOOGL\": -0.0450,     \"JPM\": 0.0000,     \"XOM\": 0.0000,     \"UNH\": 0.1172   ...\n","[LLM CALL] committee_member perspective=risk model=claude-haiku-4-5-20251001\n","[LLM CALL] committee_member perspective=cost model=claude-haiku-4-5-20251001\n","[LLM CALL] committee_member perspective=signal model=claude-haiku-4-5-20251001\n","[LLM RAW PREVIEW] risk: ```json {   \"perspective\": \"risk\",   \"proposed_trades\": {     \"AAPL\": 0.0000,     \"MSFT\": -0.0250,     \"NVDA\": -0.0200,     \"AMZN\": -0.0272,     \"GOOGL\": -0.0450,     \"JPM\": 0.0000,     \"XOM\": 0.0050,     \"UNH\": 0.0122   ...\n","[LLM RAW PREVIEW] cost: ```json {   \"perspective\": \"cost\",   \"proposed_trades\": {     \"AAPL\": -0.0125,     \"MSFT\": 0.0180,     \"NVDA\": -0.0220,     \"AMZN\": 0.0085,     \"GOOGL\": -0.0280,     \"JPM\": -0.0095,     \"XOM\": 0.0155,     \"UNH\": 0.0300   ...\n","[LLM RAW PREVIEW] signal: ```json {   \"perspective\": \"signal\",   \"proposed_trades\": {     \"AAPL\": 0.0275,     \"MSFT\": -0.0185,     \"NVDA\": -0.0220,     \"AMZN\": -0.0165,     \"GOOGL\": -0.0285,     \"JPM\": -0.0055,     \"XOM\": 0.0085,     \"UNH\": 0.015 ...\n","\n","=== Scenario C (seed=7, tighter turnover_cap=0.12) ===\n","final_decision: APPROVE\n","round: 2\n","reports_received: 6\n","errors_count: 0\n","disagreement_l1_avg: 0.11699999999999999\n","turnover: 0.11945783453142052 / 0.12\n","top_trades_abs: [('UNH', 0.0270432287835006), ('GOOGL', -0.0260817019439549), ('NVDA', -0.02151982984024342), ('XOM', 0.016063283255327614), ('AAPL', 0.014920978805716162)]\n","\n","Playground complete. Topology unchanged; only inputs/constraints varied.\n"]}]},{"cell_type":"markdown","source":["##11.CONCLUSION"],"metadata":{"id":"ZmL0B12KjLXl"}},{"cell_type":"markdown","source":["**Conclusion — From Single-Gate Decisions to Parallel Institutional Judgment**\n","\n","This notebook marks a clear shift in the project’s progression: we move from “one agent reasoning through a workflow” to a structure that behaves like a real investment organization. The rebalance problem is not framed as a single-answer question. It is framed as a committee process under constraints, where the primary objective is not persuasion but **reviewable convergence**. The architecture you built here is a formalization of how professional teams actually decide: intake, parallel perspective work, deterministic aggregation, and a stage gate that either approves or escalates.\n","\n","At the structural level, the model is a **Map–Reduce committee** wrapped inside a governed state machine. The intake node establishes the shared “meeting pack” in state: synthetic portfolio weights, constraints, and a market snapshot. Then the graph fans out into parallel committee branches: risk, cost, and signal. Each branch invokes the LLM as a specialized analyst with a narrow mandate and strict JSON outputs. Those reports are merged safely using explicit merge channels in the TypedDict state (the notebook makes concurrency a first-class concept rather than an accident). After that, the reducer node becomes the portfolio manager’s discipline: it aggregates proposals deterministically, enforces constraints (max/min weights, turnover cap, pruning of tiny trades), and computes diagnostic scores such as disagreement. Finally, the gate node plays the role of the investment committee chair: it checks for errors, checks for high disagreement, decides whether a bounded rerun is justified, and otherwise terminates with an explicit decision. The notebook then exports the required audit artifacts—run manifest, graph spec, and final state—so the entire episode is reproducible and reviewable.\n","\n","This is real progress because the architecture is now **explicitly multi-perspective**. In earlier notebooks, you were building governed control loops, but the topology was primarily serial and centered on a single reasoning stream. Notebook 1 introduced conditional retry loops for missing information: a disciplined way to ask again, bounded and explicit, rather than silently guessing. Notebook 2 introduced a suitability boundary with hard branching and early termination: the system learned to refuse and redirect, which is a governance function, not a cleverness function. Notebook 3 introduced critique loops for evidence gaps in a credit memo: the system learned to self-audit before producing an output. Notebook 4 introduced a tool-augmented node, wrapping a backtest-style computation to keep the LLM from hallucinating numbers. Notebook 5 introduced a stateful regime machine: a structured way to handle execution and liquidity conditions as a controlled state transition problem rather than ad-hoc reasoning.\n","\n","Notebook 6 extends that trajectory by adding a new architectural dimension: **parallelism with controlled aggregation**. This is the first notebook where concurrency is not just allowed but central to the design. That matters because many real finance decisions are not “one model, one answer.” They are reconciliations: risk versus cost versus signal, compliance versus opportunity, liquidity versus conviction. Serial workflows often hide these tensions by forcing a single voice to speak in one pass. Here, the tensions are surfaced by design, because you generate multiple proposals independently and then measure the distance between them. That distance becomes a governance signal. Disagreement is no longer an invisible human feeling; it becomes a computed metric that can trigger escalation.\n","\n","The most important conceptual improvement is the division of labor between **LLM creativity and deterministic control**. Earlier notebooks already pushed toward “state drives routing, not text heuristics alone.” This notebook tightens that further: the LLM is used where human judgment belongs—proposal generation under a perspective—while the aggregation and constraint enforcement are deliberately mechanical. This is the institutional pattern you want students to internalize: don’t ask an LLM to be a risk engine, a transaction cost model, and a compliance officer simultaneously. Make it do one job, then enforce structure with deterministic code. The result is faster, safer, and easier to audit.\n","\n","In governance terms, the notebook also demonstrates maturity: it does not treat failures as exceptions to be hidden. It treats them as state updates to be recorded. Errors and trace events are merge-safe and visible. The system terminates explicitly at END. Loops are bounded and justified. Artifacts are exported by default. This is what it means to build an agentic system for finance: not a chatbot that sounds confident, but a workflow that behaves like a controlled process and produces evidence that it behaved correctly.\n","\n","So the progress here is not merely “we added a committee.” The progress is that the topology now resembles a professional institution: **multiple independent views, reconciled under rules, with explicit stopping conditions and audit outputs**. That is the difference between a clever demo and a system that can survive contact with a real investment committee.\n"],"metadata":{"id":"tv8ReGkpWL8u"}}]}